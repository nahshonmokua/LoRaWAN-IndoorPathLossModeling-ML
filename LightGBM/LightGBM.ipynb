{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "add8a05e-745f-42a8-b67f-8e486806dd9e",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: left;\">\n",
    "LightGBM for Regression \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7f466d6-a3a9-456c-9e55-710ed03e0d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for data manipulation and visualization\n",
    "import numpy as np                               # For numerical operations\n",
    "import pandas as pd                              # For data manipulation\n",
    "import matplotlib.pyplot as plt                  # For plotting\n",
    "import seaborn as sns                            # For advanced data visualization\n",
    "\n",
    "# Libraries for model building and evaluation\n",
    "from sklearn.model_selection import (              # For cross-validation, splitting data, and grid search\n",
    "    KFold, \n",
    "    train_test_split, \n",
    "    GridSearchCV\n",
    ")\n",
    "from sklearn.metrics import (                     # For model evaluation metrics\n",
    "    mean_squared_error, \n",
    "    r2_score, \n",
    "    mean_absolute_percentage_error, \n",
    "    median_absolute_error\n",
    ")\n",
    "\n",
    "# LightGBM library\n",
    "import lightgbm as lgb                            # For LightGBM Regressor\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d44557a3-9ab1-490c-82d0-c7f1cd62bfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "\n",
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 749214 entries, 0 to 749213\n",
      "Data columns (total 20 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   time         749214 non-null  object \n",
      " 1   device_id    749214 non-null  object \n",
      " 2   co2          749214 non-null  float64\n",
      " 3   humidity     749214 non-null  float64\n",
      " 4   pm25         749214 non-null  float64\n",
      " 5   pressure     749214 non-null  float64\n",
      " 6   temperature  749214 non-null  float64\n",
      " 7   rssi         749214 non-null  float64\n",
      " 8   snr          749214 non-null  float64\n",
      " 9   SF           749214 non-null  int64  \n",
      " 10  frequency    749214 non-null  float64\n",
      " 11  f_count      749214 non-null  float64\n",
      " 12  p_count      749214 non-null  float64\n",
      " 13  toa          749214 non-null  float64\n",
      " 14  distance     749214 non-null  int64  \n",
      " 15  c_walls      749214 non-null  int64  \n",
      " 16  w_walls      749214 non-null  int64  \n",
      " 17  exp_pl       749214 non-null  float64\n",
      " 18  n_power      749214 non-null  float64\n",
      " 19  esp          749214 non-null  float64\n",
      "dtypes: float64(14), int64(4), object(2)\n",
      "memory usage: 114.3+ MB\n",
      "\n",
      "First Five Rows of the Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>device_id</th>\n",
       "      <th>co2</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pm25</th>\n",
       "      <th>pressure</th>\n",
       "      <th>temperature</th>\n",
       "      <th>rssi</th>\n",
       "      <th>snr</th>\n",
       "      <th>SF</th>\n",
       "      <th>frequency</th>\n",
       "      <th>f_count</th>\n",
       "      <th>p_count</th>\n",
       "      <th>toa</th>\n",
       "      <th>distance</th>\n",
       "      <th>c_walls</th>\n",
       "      <th>w_walls</th>\n",
       "      <th>exp_pl</th>\n",
       "      <th>n_power</th>\n",
       "      <th>esp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-09-26 11:00:52.542462+00:00</td>\n",
       "      <td>ED3</td>\n",
       "      <td>633.0</td>\n",
       "      <td>54.22</td>\n",
       "      <td>0.58</td>\n",
       "      <td>300.41</td>\n",
       "      <td>23.85</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>10</td>\n",
       "      <td>867.9</td>\n",
       "      <td>94.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.452608</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>88.4</td>\n",
       "      <td>-83.454107</td>\n",
       "      <td>-71.254107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-09-26 11:01:52.383162+00:00</td>\n",
       "      <td>ED3</td>\n",
       "      <td>645.0</td>\n",
       "      <td>54.18</td>\n",
       "      <td>0.32</td>\n",
       "      <td>300.48</td>\n",
       "      <td>23.87</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>9</td>\n",
       "      <td>867.7</td>\n",
       "      <td>95.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.246784</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>91.4</td>\n",
       "      <td>-86.737602</td>\n",
       "      <td>-74.237602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-09-26 11:02:52.425491+00:00</td>\n",
       "      <td>ED3</td>\n",
       "      <td>648.0</td>\n",
       "      <td>54.23</td>\n",
       "      <td>0.58</td>\n",
       "      <td>300.50</td>\n",
       "      <td>23.88</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>9</td>\n",
       "      <td>867.1</td>\n",
       "      <td>96.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.246784</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>93.4</td>\n",
       "      <td>-88.454107</td>\n",
       "      <td>-76.254107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-09-26 11:02:52.426016+00:00</td>\n",
       "      <td>ED3</td>\n",
       "      <td>648.0</td>\n",
       "      <td>54.23</td>\n",
       "      <td>0.58</td>\n",
       "      <td>300.50</td>\n",
       "      <td>23.88</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>9</td>\n",
       "      <td>867.1</td>\n",
       "      <td>96.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.246784</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>93.4</td>\n",
       "      <td>-88.454107</td>\n",
       "      <td>-76.254107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-09-26 11:03:52.481201+00:00</td>\n",
       "      <td>ED3</td>\n",
       "      <td>645.0</td>\n",
       "      <td>54.25</td>\n",
       "      <td>0.33</td>\n",
       "      <td>300.50</td>\n",
       "      <td>23.90</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>9</td>\n",
       "      <td>868.3</td>\n",
       "      <td>97.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.246784</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>93.4</td>\n",
       "      <td>-89.403045</td>\n",
       "      <td>-76.203045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               time device_id    co2  humidity  pm25  \\\n",
       "0  2024-09-26 11:00:52.542462+00:00       ED3  633.0     54.22  0.58   \n",
       "1  2024-09-26 11:01:52.383162+00:00       ED3  645.0     54.18  0.32   \n",
       "2  2024-09-26 11:02:52.425491+00:00       ED3  648.0     54.23  0.58   \n",
       "3  2024-09-26 11:02:52.426016+00:00       ED3  648.0     54.23  0.58   \n",
       "4  2024-09-26 11:03:52.481201+00:00       ED3  645.0     54.25  0.33   \n",
       "\n",
       "   pressure  temperature  rssi   snr  SF  frequency  f_count  p_count  \\\n",
       "0    300.41        23.85 -71.0  12.2  10      867.9     94.0    104.0   \n",
       "1    300.48        23.87 -74.0  12.5   9      867.7     95.0    105.0   \n",
       "2    300.50        23.88 -76.0  12.2   9      867.1     96.0    106.0   \n",
       "3    300.50        23.88 -76.0  12.2   9      867.1     96.0    106.0   \n",
       "4    300.50        23.90 -76.0  13.2   9      868.3     97.0    107.0   \n",
       "\n",
       "        toa  distance  c_walls  w_walls  exp_pl    n_power        esp  \n",
       "0  0.452608        18        1        2    88.4 -83.454107 -71.254107  \n",
       "1  0.246784        18        1        2    91.4 -86.737602 -74.237602  \n",
       "2  0.246784        18        1        2    93.4 -88.454107 -76.254107  \n",
       "3  0.246784        18        1        2    93.4 -88.454107 -76.254107  \n",
       "4  0.246784        18        1        2    93.4 -89.403045 -76.203045  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the path to the dataset\n",
    "dataset_path = '../../all_data_files/cleaned_dataset_per_device.csv'\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found at the specified path: {dataset_path}\")\n",
    "    import sys\n",
    "    sys.exit()\n",
    "\n",
    "# Display dataset information\n",
    "print(\"\\nDataset Information:\")\n",
    "df.info()\n",
    "print(\"\\nFirst Five Rows of the Dataset:\")\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c06491f8-bf9a-41d6-9474-6e558d9d6d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-test split completed.\n"
     ]
    }
   ],
   "source": [
    "# Define feature columns and target\n",
    "feature_columns = [\n",
    "    'distance', 'frequency', 'c_walls', 'w_walls', \n",
    "    'co2', 'humidity', 'pm25', 'pressure', \n",
    "    'temperature', 'snr'\n",
    "]\n",
    "target_column = 'exp_pl'\n",
    "\n",
    "# Verify that all required columns exist\n",
    "missing_columns = set(feature_columns + [target_column]) - set(df.columns)\n",
    "if missing_columns:\n",
    "    raise ValueError(f\"The following required columns are missing in the dataset: {missing_columns}\")\n",
    "\n",
    "# Extract features and target\n",
    "all_features = df[feature_columns].values\n",
    "PL_all = df[target_column].values\n",
    "\n",
    "# Perform train-test split (80-20 split)\n",
    "X_train_all, X_test_all, PL_train_all, PL_test_all = train_test_split(\n",
    "    all_features, PL_all, test_size=0.2, random_state=50\n",
    ")\n",
    "\n",
    "print(\"Train-test split completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfa9051-9b65-45eb-8e86-a7728d449eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Grid Search for max_depth=1...\n",
      "Fitting 5 folds for each of 6561 candidates, totalling 32805 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The LGBMRegressor or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the fixed max_depth values\n",
    "max_depth_values = [1, 2, 3]\n",
    "\n",
    "# Define other hyperparameters for grid search\n",
    "param_grid = {\n",
    "    'num_leaves': [31, 50, 100],                  # Number of leaves in one tree\n",
    "    'learning_rate': [0.01, 0.1, 0.2],            # Step size shrinkage\n",
    "    'n_estimators': [100, 200, 300],              # Number of boosting iterations\n",
    "    'subsample': [0.6, 0.8, 1.0],                 # Subsample ratio of the training instances\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],          # Subsample ratio of columns when constructing each tree\n",
    "    'min_child_weight': [1, 2, 4],                # Minimum sum of instance weight (hessian) needed in a child\n",
    "    'reg_alpha': [0, 0.1, 0.5],                   # L1 regularization term on weights\n",
    "    'reg_lambda': [0, 0.1, 0.5]                   # L2 regularization term on weights\n",
    "}\n",
    "\n",
    "# Dictionary to store the best models for each max_depth\n",
    "best_models = {}\n",
    "best_params_per_depth = {}\n",
    "best_scores_per_depth = {}\n",
    "\n",
    "# Iterate over each max_depth and perform grid search\n",
    "for depth in max_depth_values:\n",
    "    print(f\"\\nPerforming Grid Search for max_depth={depth}...\")\n",
    "    \n",
    "    # Create a base LightGBM Regressor with the current max_depth\n",
    "    lgb_reg = lgb.LGBMRegressor(\n",
    "        max_depth=depth,\n",
    "        objective='regression',                       # Regression task\n",
    "        random_state=50, \n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Initialize Grid Search\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=lgb_reg,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,                                         # 5-fold cross-validation\n",
    "        scoring='neg_mean_squared_error',             # Using negative MSE for comparison\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Perform Grid Search\n",
    "    grid_search.fit(X_train_all, PL_train_all)\n",
    "    \n",
    "    # Retrieve the best parameters and corresponding score\n",
    "    best_params = grid_search.best_params_\n",
    "    best_neg_mse = grid_search.best_score_\n",
    "    best_mse = -best_neg_mse  # Convert from negative MSE to MSE\n",
    "    \n",
    "    best_models[depth] = grid_search.best_estimator_\n",
    "    best_params_per_depth[depth] = best_params\n",
    "    best_scores_per_depth[depth] = best_mse\n",
    "    \n",
    "    print(f\"Best Parameters for max_depth={depth}: {best_params}\")\n",
    "    print(f\"Best CV MSE for max_depth={depth}: {best_mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f2a249-b743-4e38-84d2-732857079fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store evaluation metrics for each model\n",
    "evaluation_metrics = []\n",
    "\n",
    "for depth in max_depth_values:\n",
    "    model = best_models[depth]\n",
    "    params = best_params_per_depth[depth]\n",
    "    \n",
    "    print(f\"\\nEvaluating model with max_depth={depth} and parameters: {params}\")\n",
    "    \n",
    "    # Train the model on the entire training set\n",
    "    model.fit(X_train_all, PL_train_all)\n",
    "    \n",
    "    # Retrieve OOB score if applicable (LightGBM does not have OOB, but can use other metrics)\n",
    "    # Instead, we'll use the training data evaluation\n",
    "    # Make predictions\n",
    "    PL_train_pred = model.predict(X_train_all)\n",
    "    PL_test_pred = model.predict(X_test_all)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_mse = mean_squared_error(PL_train_all, PL_train_pred)\n",
    "    test_mse = mean_squared_error(PL_test_all, PL_test_pred)\n",
    "    train_r2 = r2_score(PL_train_all, PL_train_pred)\n",
    "    test_r2 = r2_score(PL_test_all, PL_test_pred)\n",
    "    test_rmse = np.sqrt(test_mse)\n",
    "    test_mape = mean_absolute_percentage_error(PL_test_all, PL_test_pred)\n",
    "    test_median_ae = median_absolute_error(PL_test_all, PL_test_pred)\n",
    "    \n",
    "    # Append metrics to the list\n",
    "    evaluation_metrics.append({\n",
    "        'max_depth': depth,\n",
    "        'Training Loss (MSE)': train_mse,\n",
    "        'Test Loss (MSE)': test_mse,\n",
    "        'Test RMSE': test_rmse,\n",
    "        'R² Score': test_r2,\n",
    "        'Test MAPE (%)': test_mape * 100,\n",
    "        'Test Median AE': test_median_ae\n",
    "    })\n",
    "    \n",
    "    print(f\"Model with max_depth={depth} - Training MSE: {train_mse:.4f}, Test MSE: {test_mse:.4f}\")\n",
    "    print(f\"Training R²: {train_r2:.4f}, Test R²: {test_r2:.4f}\")\n",
    "    print(f\"Test RMSE: {test_rmse:.4f}, Test MAPE: {test_mape*100:.2f}%, Test Median AE: {test_median_ae:.4f}\")\n",
    "    \n",
    "# Create a results DataFrame\n",
    "results_df = pd.DataFrame(evaluation_metrics)\n",
    "\n",
    "print(\"\\nModel Evaluation Metrics for Best Models per max_depth:\")\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723fe50e-4e12-4ec6-95cd-66378827f969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of models\n",
    "num_models = len(max_depth_values)\n",
    "\n",
    "# Set up the subplot grid (1 row, 3 columns)\n",
    "fig, axes = plt.subplots(1, num_models, figsize=(18, 5), sharey=True)\n",
    "\n",
    "# If only one subplot, make axes iterable\n",
    "if num_models == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, depth in zip(axes, max_depth_values):\n",
    "    model = best_models[depth]\n",
    "    PL_test_pred = model.predict(X_test_all)\n",
    "    \n",
    "    sns.scatterplot(x=PL_test_all, y=PL_test_pred, alpha=0.5, edgecolor='w', s=50, ax=ax)\n",
    "    ax.plot([PL_test_all.min(), PL_test_all.max()], [PL_test_all.min(), PL_test_all.max()], 'r--', lw=2)\n",
    "    ax.set_xlabel('Actual Path Loss')\n",
    "    ax.set_ylabel('Predicted Path Loss')\n",
    "    ax.set_title(f'Actual vs Predicted Path Loss (max_depth={depth})')\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b49ae8e-29a5-4b62-a1e4-306362c2ab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of folds for cross-validation\n",
    "n_folds = 5\n",
    "\n",
    "# Initialize KFold\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Dictionary to store cross-validation results\n",
    "cv_results_dict = {depth: [] for depth in max_depth_values}\n",
    "\n",
    "print(\"\\nPerforming K-Fold Cross-Validation for Each Best Model...\\n\")\n",
    "\n",
    "for depth in max_depth_values:\n",
    "    model = best_models[depth]\n",
    "    params = best_params_per_depth[depth]\n",
    "    \n",
    "    print(f\"Cross-Validation for max_depth={depth} with parameters: {params}\")\n",
    "    \n",
    "    fold = 1\n",
    "    for train_idx, val_idx in kf.split(X_train_all):\n",
    "        print(f\"  Training fold {fold}...\")\n",
    "        \n",
    "        # Split the data for the current fold\n",
    "        X_train_fold, X_val_fold = X_train_all[train_idx], X_train_all[val_idx]\n",
    "        PL_train_fold, PL_val_fold = PL_train_all[train_idx], PL_train_all[val_idx]\n",
    "        \n",
    "        # Instantiate a new model with the best parameters\n",
    "        lgb_cv = lgb.LGBMRegressor(\n",
    "            max_depth=depth,\n",
    "            num_leaves=params['num_leaves'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            n_estimators=params['n_estimators'],\n",
    "            subsample=params['subsample'],\n",
    "            colsample_bytree=params['colsample_bytree'],\n",
    "            min_child_weight=params['min_child_weight'],\n",
    "            reg_alpha=params['reg_alpha'],\n",
    "            reg_lambda=params['reg_lambda'],\n",
    "            objective='regression',\n",
    "            random_state=50, \n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        # Train the model on the current fold\n",
    "        lgb_cv.fit(X_train_fold, PL_train_fold)\n",
    "        \n",
    "        # Predict on validation set\n",
    "        PL_val_pred = lgb_cv.predict(X_val_fold)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        val_mse = mean_squared_error(PL_val_fold, PL_val_pred)\n",
    "        val_rmse = np.sqrt(val_mse)\n",
    "        val_r2 = r2_score(PL_val_fold, PL_val_pred)\n",
    "        val_mape = mean_absolute_percentage_error(PL_val_fold, PL_val_pred)\n",
    "        val_median_ae = median_absolute_error(PL_val_fold, PL_val_pred)\n",
    "        \n",
    "        # Append metrics to the dictionary\n",
    "        cv_results_dict[depth].append({\n",
    "            'Fold': fold,\n",
    "            'Validation Loss (MSE)': round(val_mse, 4),\n",
    "            'Validation RMSE': round(val_rmse, 4),\n",
    "            'R² Score': round(val_r2, 4),\n",
    "            'Validation MAPE (%)': round(val_mape * 100, 2),\n",
    "            'Validation Median AE': round(val_median_ae, 4)\n",
    "        })\n",
    "        \n",
    "        print(f\"    Fold {fold} - MSE: {val_mse:.4f}, RMSE: {val_rmse:.4f}, R²: {val_r2:.4f}, MAPE: {val_mape*100:.2f}%, Median AE: {val_median_ae:.4f}\\n\")\n",
    "        fold += 1\n",
    "\n",
    "# Create a DataFrame for each max_depth's CV results and display them\n",
    "for depth in max_depth_values:\n",
    "    print(f\"\\nK-Fold Cross-Validation Results for max_depth={depth}:\")\n",
    "    cv_results_df = pd.DataFrame(cv_results_dict[depth])\n",
    "    display(cv_results_df)\n",
    "    \n",
    "    # Summary statistics\n",
    "    cv_summary = cv_results_df.agg(['mean', 'std']).round(4).reset_index()\n",
    "    cv_summary.rename(columns={'index': 'Metric'}, inplace=True)\n",
    "    print(f\"\\nCross-Validation Summary for max_depth={depth}:\")\n",
    "    display(cv_summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_models_env)",
   "language": "python",
   "name": "ml_models_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
