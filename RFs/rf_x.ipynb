{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fd65fa2-6937-4a92-887f-41f444941f6f",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: left;\">\n",
    "Random Forest (RF) Modeling \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "782c5ddf-f7dc-4c04-a463-83d110363b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for data manipulation and visualization\n",
    "import numpy as np                               # For numerical operations\n",
    "import pandas as pd                              # For data manipulation\n",
    "import matplotlib.pyplot as plt                  # For plotting\n",
    "import seaborn as sns                            # For advanced data visualization\n",
    "\n",
    "# Libraries for model building and evaluation\n",
    "from sklearn.ensemble import RandomForestRegressor  # For Random Forest Regression\n",
    "from sklearn.metrics import (                     # For model evaluation metrics\n",
    "    mean_squared_error, \n",
    "    r2_score, \n",
    "    mean_absolute_percentage_error, \n",
    "    median_absolute_error\n",
    ")\n",
    "from sklearn.model_selection import (              # For cross-validation, splitting data, and grid search\n",
    "    KFold, \n",
    "    train_test_split, \n",
    "    GridSearchCV\n",
    ")\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04d9ec00-6549-4d2c-b3de-d001ed0e5763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "\n",
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 554505 entries, 0 to 554504\n",
      "Data columns (total 20 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   time         554505 non-null  object \n",
      " 1   device_id    554505 non-null  object \n",
      " 2   co2          554505 non-null  float64\n",
      " 3   humidity     554505 non-null  float64\n",
      " 4   pm25         554505 non-null  float64\n",
      " 5   pressure     554505 non-null  float64\n",
      " 6   temperature  554505 non-null  float64\n",
      " 7   rssi         554505 non-null  float64\n",
      " 8   snr          554505 non-null  float64\n",
      " 9   SF           554505 non-null  int64  \n",
      " 10  frequency    554505 non-null  float64\n",
      " 11  f_count      554505 non-null  float64\n",
      " 12  p_count      554505 non-null  float64\n",
      " 13  toa          554505 non-null  float64\n",
      " 14  distance     554505 non-null  int64  \n",
      " 15  c_walls      554505 non-null  int64  \n",
      " 16  w_walls      554505 non-null  int64  \n",
      " 17  exp_pl       554505 non-null  float64\n",
      " 18  n_power      554505 non-null  float64\n",
      " 19  esp          554505 non-null  float64\n",
      "dtypes: float64(14), int64(4), object(2)\n",
      "memory usage: 84.6+ MB\n",
      "\n",
      "First Five Rows of the Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>device_id</th>\n",
       "      <th>co2</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pm25</th>\n",
       "      <th>pressure</th>\n",
       "      <th>temperature</th>\n",
       "      <th>rssi</th>\n",
       "      <th>snr</th>\n",
       "      <th>SF</th>\n",
       "      <th>frequency</th>\n",
       "      <th>f_count</th>\n",
       "      <th>p_count</th>\n",
       "      <th>toa</th>\n",
       "      <th>distance</th>\n",
       "      <th>c_walls</th>\n",
       "      <th>w_walls</th>\n",
       "      <th>exp_pl</th>\n",
       "      <th>n_power</th>\n",
       "      <th>esp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-09-26 11:02:08.387851+00:00</td>\n",
       "      <td>ED0</td>\n",
       "      <td>539.0</td>\n",
       "      <td>49.34</td>\n",
       "      <td>0.39</td>\n",
       "      <td>299.69</td>\n",
       "      <td>24.57</td>\n",
       "      <td>-48.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>9</td>\n",
       "      <td>867.5</td>\n",
       "      <td>82.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.246784</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65.4</td>\n",
       "      <td>-57.073822</td>\n",
       "      <td>-48.573822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-09-26 11:03:08.309590+00:00</td>\n",
       "      <td>ED0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>49.33</td>\n",
       "      <td>0.80</td>\n",
       "      <td>299.77</td>\n",
       "      <td>24.59</td>\n",
       "      <td>-48.0</td>\n",
       "      <td>12.8</td>\n",
       "      <td>8</td>\n",
       "      <td>867.3</td>\n",
       "      <td>83.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.133632</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65.4</td>\n",
       "      <td>-61.022142</td>\n",
       "      <td>-48.222142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-09-26 11:04:08.368448+00:00</td>\n",
       "      <td>ED0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>49.28</td>\n",
       "      <td>0.71</td>\n",
       "      <td>299.70</td>\n",
       "      <td>24.62</td>\n",
       "      <td>-48.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>868.5</td>\n",
       "      <td>84.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.133632</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65.4</td>\n",
       "      <td>-56.638920</td>\n",
       "      <td>-48.638920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-09-26 11:05:08.405529+00:00</td>\n",
       "      <td>ED0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>49.34</td>\n",
       "      <td>0.56</td>\n",
       "      <td>299.69</td>\n",
       "      <td>24.63</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8</td>\n",
       "      <td>867.9</td>\n",
       "      <td>85.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.133632</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66.4</td>\n",
       "      <td>-60.331956</td>\n",
       "      <td>-49.331956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-09-26 11:06:08.455112+00:00</td>\n",
       "      <td>ED0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>49.28</td>\n",
       "      <td>0.60</td>\n",
       "      <td>299.73</td>\n",
       "      <td>24.64</td>\n",
       "      <td>-46.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>8</td>\n",
       "      <td>867.5</td>\n",
       "      <td>86.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0.133632</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63.4</td>\n",
       "      <td>-55.693058</td>\n",
       "      <td>-46.493058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               time device_id    co2  humidity  pm25  \\\n",
       "0  2024-09-26 11:02:08.387851+00:00       ED0  539.0     49.34  0.39   \n",
       "1  2024-09-26 11:03:08.309590+00:00       ED0  540.0     49.33  0.80   \n",
       "2  2024-09-26 11:04:08.368448+00:00       ED0  537.0     49.28  0.71   \n",
       "3  2024-09-26 11:05:08.405529+00:00       ED0  537.0     49.34  0.56   \n",
       "4  2024-09-26 11:06:08.455112+00:00       ED0  534.0     49.28  0.60   \n",
       "\n",
       "   pressure  temperature  rssi   snr  SF  frequency  f_count  p_count  \\\n",
       "0    299.69        24.57 -48.0   8.5   9      867.5     82.0    109.0   \n",
       "1    299.77        24.59 -48.0  12.8   8      867.3     83.0    110.0   \n",
       "2    299.70        24.62 -48.0   8.0   8      868.5     84.0    111.0   \n",
       "3    299.69        24.63 -49.0  11.0   8      867.9     85.0    112.0   \n",
       "4    299.73        24.64 -46.0   9.2   8      867.5     86.0    113.0   \n",
       "\n",
       "        toa  distance  c_walls  w_walls  exp_pl    n_power        esp  \n",
       "0  0.246784        10        0        0    65.4 -57.073822 -48.573822  \n",
       "1  0.133632        10        0        0    65.4 -61.022142 -48.222142  \n",
       "2  0.133632        10        0        0    65.4 -56.638920 -48.638920  \n",
       "3  0.133632        10        0        0    66.4 -60.331956 -49.331956  \n",
       "4  0.133632        10        0        0    63.4 -55.693058 -46.493058  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the path to the dataset\n",
    "dataset_path = '../../all_data_files/cleaned_dataset_per_device.csv'\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found at the specified path: {dataset_path}\")\n",
    "    import sys\n",
    "    sys.exit()\n",
    "\n",
    "# Display dataset information\n",
    "print(\"\\nDataset Information:\")\n",
    "df.info()\n",
    "print(\"\\nFirst Five Rows of the Dataset:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2f822e2-7076-4e4c-821c-f1dd737a4a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-test split completed.\n"
     ]
    }
   ],
   "source": [
    "# Define feature columns and target\n",
    "feature_columns = [\n",
    "    'distance', 'frequency', 'c_walls', 'w_walls', \n",
    "    'co2', 'humidity', 'pm25', 'pressure', \n",
    "    'temperature', 'snr'\n",
    "]\n",
    "target_column = 'exp_pl'\n",
    "\n",
    "# Verify that all required columns exist\n",
    "missing_columns = set(feature_columns + [target_column]) - set(df.columns)\n",
    "if missing_columns:\n",
    "    raise ValueError(f\"The following required columns are missing in the dataset: {missing_columns}\")\n",
    "\n",
    "# Extract features and target\n",
    "all_features = df[feature_columns].values\n",
    "PL_all = df[target_column].values\n",
    "\n",
    "# Perform train-test split (80-20 split)\n",
    "X_train_all, X_test_all, PL_train_all, PL_test_all = train_test_split(\n",
    "    all_features, PL_all, test_size=0.2, random_state=50\n",
    ")\n",
    "\n",
    "print(\"Train-test split completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7f8e5b-0857-44a6-9e56-696277d83b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Grid Search for max_depth=1...\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    }
   ],
   "source": [
    "# Define the fixed max_depth values\n",
    "max_depth_values = [1, 2, 3]\n",
    "\n",
    "# Define other hyperparameters for grid search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],            # Number of trees in the forest\n",
    "    'min_samples_split': [2, 10, 100],         # Minimum samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4]              # Minimum samples required at a leaf node\n",
    "}\n",
    "\n",
    "# Dictionary to store the best models for each max_depth\n",
    "best_models = {}\n",
    "best_params_per_depth = {}\n",
    "best_scores_per_depth = {}\n",
    "\n",
    "# Iterate over each max_depth and perform grid search\n",
    "for depth in max_depth_values:\n",
    "    print(f\"\\nPerforming Grid Search for max_depth={depth}...\")\n",
    "    \n",
    "    # Create a base Random Forest Regressor with the current max_depth\n",
    "    rf = RandomForestRegressor(\n",
    "        max_depth=depth,\n",
    "        criterion='squared_error',                # Fixed criterion\n",
    "        max_features='log2',                      # Fixed max_features\n",
    "        min_impurity_decrease=0.001,              # Fixed min_impurity_decrease\n",
    "        random_state=50, \n",
    "        n_jobs=-1, \n",
    "        bootstrap=True, \n",
    "        oob_score=True\n",
    "    )\n",
    "    \n",
    "    # Initialize Grid Search\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=rf,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,                                       # 5-fold cross-validation\n",
    "        scoring='neg_mean_squared_error',           # Using negative MSE for comparison\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Perform Grid Search\n",
    "    grid_search.fit(X_train_all, PL_train_all)\n",
    "    \n",
    "    # Retrieve the best parameters and corresponding score\n",
    "    best_params = grid_search.best_params_\n",
    "    best_neg_mse = grid_search.best_score_\n",
    "    best_mse = -best_neg_mse  # Convert from negative MSE to MSE\n",
    "    \n",
    "    best_models[depth] = grid_search.best_estimator_\n",
    "    best_params_per_depth[depth] = best_params\n",
    "    best_scores_per_depth[depth] = best_mse\n",
    "    \n",
    "    print(f\"Best Parameters for max_depth={depth}: {best_params}\")\n",
    "    print(f\"Best CV MSE for max_depth={depth}: {best_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76d54ad-90af-4ef0-98f1-ba0673fb08f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store evaluation metrics for each model\n",
    "evaluation_metrics = []\n",
    "\n",
    "for depth in max_depth_values:\n",
    "    model = best_models[depth]\n",
    "    params = best_params_per_depth[depth]\n",
    "    \n",
    "    print(f\"\\nEvaluating model with max_depth={depth} and parameters: {params}\")\n",
    "    \n",
    "    # Train the model on the entire training set\n",
    "    model.fit(X_train_all, PL_train_all)\n",
    "    \n",
    "    # Retrieve OOB score\n",
    "    oob_score = model.oob_score_\n",
    "    \n",
    "    # Make predictions\n",
    "    PL_train_pred = model.predict(X_train_all)\n",
    "    PL_test_pred = model.predict(X_test_all)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_mse = mean_squared_error(PL_train_all, PL_train_pred)\n",
    "    test_mse = mean_squared_error(PL_test_all, PL_test_pred)\n",
    "    train_r2 = r2_score(PL_train_all, PL_train_pred)\n",
    "    test_r2 = r2_score(PL_test_all, PL_test_pred)\n",
    "    test_rmse = np.sqrt(test_mse)\n",
    "    test_mape = mean_absolute_percentage_error(PL_test_all, PL_test_pred)\n",
    "    test_median_ae = median_absolute_error(PL_test_all, PL_test_pred)\n",
    "    \n",
    "    # Append metrics to the list\n",
    "    evaluation_metrics.append({\n",
    "        'max_depth': depth,\n",
    "        'OOB Score': oob_score,\n",
    "        'Training Loss (MSE)': train_mse,\n",
    "        'Test Loss (MSE)': test_mse,\n",
    "        'Test RMSE': test_rmse,\n",
    "        'R² Score': test_r2,\n",
    "        'Test MAPE (%)': test_mape * 100,\n",
    "        'Test Median AE': test_median_ae\n",
    "    })\n",
    "    \n",
    "    print(f\"Model with max_depth={depth} - OOB Score: {oob_score:.4f}\")\n",
    "    print(f\"Training MSE: {train_mse:.4f}, Test MSE: {test_mse:.4f}\")\n",
    "    print(f\"Training R²: {train_r2:.4f}, Test R²: {test_r2:.4f}\")\n",
    "    print(f\"Test RMSE: {test_rmse:.4f}, Test MAPE: {test_mape*100:.2f}%, Test Median AE: {test_median_ae:.4f}\")\n",
    "    \n",
    "# Create a results DataFrame\n",
    "results_df = pd.DataFrame(evaluation_metrics)\n",
    "\n",
    "print(\"\\nModel Evaluation Metrics for Best Models per max_depth:\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc81037-f287-44dd-93c4-091d2edf5a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of models\n",
    "num_models = len(max_depth_values)\n",
    "\n",
    "# Set up the subplot grid (1 row, 3 columns)\n",
    "fig, axes = plt.subplots(1, num_models, figsize=(18, 5), sharey=True)\n",
    "\n",
    "# If only one subplot, make axes iterable\n",
    "if num_models == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, depth in zip(axes, max_depth_values):\n",
    "    model = best_models[depth]\n",
    "    PL_test_pred = model.predict(X_test_all)\n",
    "    \n",
    "    sns.scatterplot(x=PL_test_all, y=PL_test_pred, alpha=0.5, edgecolor='w', s=50, ax=ax)\n",
    "    ax.plot([PL_test_all.min(), PL_test_all.max()], [PL_test_all.min(), PL_test_all.max()], 'r--', lw=2)\n",
    "    ax.set_xlabel('Actual Path Loss')\n",
    "    ax.set_ylabel('Predicted Path Loss')\n",
    "    ax.set_title(f'Actual vs Predicted Path Loss (max_depth={depth})')\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d78693-438a-4561-863c-1dce5e286289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of folds for cross-validation\n",
    "n_folds = 5\n",
    "\n",
    "# Initialize KFold\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Dictionary to store cross-validation results\n",
    "cv_results_dict = {depth: [] for depth in max_depth_values}\n",
    "\n",
    "print(\"\\nPerforming K-Fold Cross-Validation for Each Best Model...\\n\")\n",
    "\n",
    "for depth in max_depth_values:\n",
    "    model = best_models[depth]\n",
    "    params = best_params_per_depth[depth]\n",
    "    \n",
    "    print(f\"Cross-Validation for max_depth={depth} with parameters: {params}\")\n",
    "    \n",
    "    fold = 1\n",
    "    for train_idx, val_idx in kf.split(X_train_all):\n",
    "        print(f\"  Training fold {fold}...\")\n",
    "        \n",
    "        # Split the data for the current fold\n",
    "        X_train_fold, X_val_fold = X_train_all[train_idx], X_train_all[val_idx]\n",
    "        PL_train_fold, PL_val_fold = PL_train_all[train_idx], PL_train_all[val_idx]\n",
    "        \n",
    "        # Instantiate a new model with the best parameters\n",
    "        rf_cv = RandomForestRegressor(\n",
    "            max_depth=depth,\n",
    "            criterion='squared_error',                # Fixed criterion\n",
    "            max_features='log2',                      # Fixed max_features\n",
    "            min_impurity_decrease=0.001,              # Fixed min_impurity_decrease\n",
    "            n_estimators=params['n_estimators'],\n",
    "            min_samples_split=params['min_samples_split'],\n",
    "            min_samples_leaf=params['min_samples_leaf'],\n",
    "            random_state=50, \n",
    "            n_jobs=-1, \n",
    "            bootstrap=True, \n",
    "            oob_score=True\n",
    "        )\n",
    "        \n",
    "        # Train the model on the current fold\n",
    "        rf_cv.fit(X_train_fold, PL_train_fold)\n",
    "        \n",
    "        # Predict on validation set\n",
    "        PL_val_pred = rf_cv.predict(X_val_fold)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        val_mse = mean_squared_error(PL_val_fold, PL_val_pred)\n",
    "        val_rmse = np.sqrt(val_mse)\n",
    "        val_r2 = r2_score(PL_val_fold, PL_val_pred)\n",
    "        val_mape = mean_absolute_percentage_error(PL_val_fold, PL_val_pred)\n",
    "        val_median_ae = median_absolute_error(PL_val_fold, PL_val_pred)\n",
    "        \n",
    "        # Append metrics to the dictionary\n",
    "        cv_results_dict[depth].append({\n",
    "            'Fold': fold,\n",
    "            'Validation Loss (MSE)': round(val_mse, 4),\n",
    "            'Validation RMSE': round(val_rmse, 4),\n",
    "            'R² Score': round(val_r2, 4),\n",
    "            'Validation MAPE (%)': round(val_mape * 100, 2),\n",
    "            'Validation Median AE': round(val_median_ae, 4)\n",
    "        })\n",
    "        \n",
    "        print(f\"    Fold {fold} - MSE: {val_mse:.4f}, RMSE: {val_rmse:.4f}, R²: {val_r2:.4f}, MAPE: {val_mape*100:.2f}%, Median AE: {val_median_ae:.4f}\\n\")\n",
    "        fold += 1\n",
    "\n",
    "# Create a DataFrame for each max_depth's CV results and display them\n",
    "for depth in max_depth_values:\n",
    "    print(f\"\\nK-Fold Cross-Validation Results for max_depth={depth}:\")\n",
    "    cv_results_df = pd.DataFrame(cv_results_dict[depth])\n",
    "    display(cv_results_df)\n",
    "    \n",
    "    # Summary statistics\n",
    "    cv_summary = cv_results_df.agg(['mean', 'std']).round(4).reset_index()\n",
    "    cv_summary.rename(columns={'index': 'Metric'}, inplace=True)\n",
    "    print(f\"\\nCross-Validation Summary for max_depth={depth}:\")\n",
    "    display(cv_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_models_env)",
   "language": "python",
   "name": "ml_models_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
