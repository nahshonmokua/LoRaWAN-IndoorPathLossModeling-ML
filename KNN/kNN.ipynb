{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a07a16ec",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: left;\">\n",
    "k-NN for Regression \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecdb80e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for data manipulation and visualization\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# KNN + pipeline + preprocessing\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "# Model selection & evaluation\n",
    "from sklearn.model_selection import PredefinedSplit, learning_curve\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, r2_score, mean_absolute_percentage_error, median_absolute_error\n",
    ")\n",
    "\n",
    "# Bayesian hyperparameter search\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer, Real, Categorical\n",
    "\n",
    "# For the physics-consistency check\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# For pretty display (as in your RF cell)\n",
    "from IPython.display import display\n",
    "\n",
    "# Housekeeping\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='skopt')\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e084540f",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: left;\">\n",
    "Load data & folds\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd32de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1663627 rows, Test: 415907 rows\n",
      "Train window: 2024-10-01 00:01:07.420593+00:00 -> 2025-08-12 17:18:53.293125+00:00\n",
      "Test window:  2025-08-12 17:19:02.126782+00:00 -> 2025-09-30 23:59:55.971870+00:00\n"
     ]
    }
   ],
   "source": [
    "# Time-aware data load (from Data Preparation.ipynb outputs)\n",
    "\n",
    "base_path = '../../Comprehensive ML - Files & Plots etc' \n",
    "\n",
    "df_train = pd.read_csv(f\"{base_path}/train.csv\", parse_dates=['time'])\n",
    "df_test  = pd.read_csv(f\"{base_path}/test.csv\", parse_dates=['time'])\n",
    "fold_assignments = np.load(f\"{base_path}/train_folds.npy\")\n",
    "\n",
    "feature_names = [\n",
    "    'distance', 'frequency', 'c_walls', 'w_walls', 'co2', 'humidity',\n",
    "    'pm25', 'pressure', 'temperature', 'snr'\n",
    "]\n",
    "\n",
    "X_train = df_train[feature_names].to_numpy()\n",
    "y_train = df_train['PL'].to_numpy()\n",
    "X_test  = df_test[feature_names].to_numpy()\n",
    "y_test  = df_test['PL'].to_numpy()\n",
    "\n",
    "time_train = df_train['time'].to_numpy()\n",
    "time_test  = df_test['time'].to_numpy()\n",
    "\n",
    "ps = PredefinedSplit(fold_assignments)  # reuse the time-aware folds\n",
    "\n",
    "print(f\"Train: {len(df_train)} rows, Test: {len(df_test)} rows\")\n",
    "print(f\"Train window: {df_train.time.min()} -> {df_train.time.max()}\")\n",
    "print(f\"Test window:  {df_test.time.min()} -> {df_test.time.max()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: left;\">\n",
    "KNN pipeline & search space</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ade786bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline: scaler (tuned) + KNN\n",
    "def create_knn_pipeline():\n",
    "    return Pipeline([\n",
    "        ('scaler', StandardScaler()),  # default; will be overridden by search\n",
    "        ('knn', KNeighborsRegressor(\n",
    "            metric='minkowski',\n",
    "            n_jobs=4     # leverage parallelism where applicable\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "# Bayesian search space (mirrors your RF approach in spirit)\n",
    "# - We tune K broadly but bounded (1..200) for tractability.\n",
    "# - We also tune weighting, Minkowski p (L1 vs L2), algorithm, leaf_size, and the scaler choice.\n",
    "search_spaces = {\n",
    "    'scaler': Categorical([\n",
    "        StandardScaler(),\n",
    "        RobustScaler(quantile_range=(10.0, 90.0))\n",
    "    ]),\n",
    "    'knn__n_neighbors': Integer(1, 200),\n",
    "    'knn__weights': Categorical(['uniform', 'distance']),\n",
    "    'knn__p': Integer(1, 2),  # 1=Manhattan, 2=Euclidean\n",
    "    'knn__algorithm': Categorical(['auto', 'ball_tree', 'kd_tree', 'brute']),\n",
    "    'knn__leaf_size': Integer(20, 100)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: left;\">\n",
    "CV setup, Bayesian optimization, and CV summary per K\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba10496a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Bayesian optimization with 35 iterations and 5-fold CV per candidate...\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    }
   ],
   "source": [
    "# ---- Multi-metric scoring (same as RF) ----\n",
    "scoring = {\n",
    "    'neg_root_mean_squared_error': 'neg_root_mean_squared_error',\n",
    "    'r2': 'r2'\n",
    "}\n",
    "\n",
    "# ---- PredefinedSplit (use provided fold assignments) ----\n",
    "ps = PredefinedSplit(fold_assignments)\n",
    "\n",
    "# ---- Bayesian optimization ----\n",
    "bayes_cv_knn = BayesSearchCV(\n",
    "    estimator=create_knn_pipeline(),\n",
    "    search_spaces=search_spaces,\n",
    "    n_iter=35,                        # increase/decrease for runtime\n",
    "    scoring=scoring,\n",
    "    refit='neg_root_mean_squared_error',\n",
    "    n_jobs=8,\n",
    "    cv=ps,\n",
    "    random_state=42,\n",
    "    verbose=2,\n",
    "    n_points=4,\n",
    "    optimizer_kwargs={'n_initial_points': 12, 'acq_func': 'gp_hedge'}\n",
    ")\n",
    "\n",
    "print(f\"Starting Bayesian optimization with {bayes_cv_knn.n_iter} iterations \"\n",
    "      f\"and {ps.get_n_splits()}-fold CV per candidate...\")\n",
    "\n",
    "# ---- Fit Bayesian optimizer on training data ----\n",
    "bayes_cv_knn.fit(X_train, y_train)\n",
    "\n",
    "print(\"Bayesian optimization complete. Extracting results...\")\n",
    "\n",
    "# ---- Pull all tried configs/results into a dataframe ----\n",
    "bayes_results_knn = pd.DataFrame(bayes_cv_knn.cv_results_).copy()\n",
    "\n",
    "# ---- For each K, track best results (similar to your 'per-depth' RF view) ----\n",
    "cv_summary_per_k = []\n",
    "\n",
    "# Ensure K is integer for sorting\n",
    "if 'param_knn__n_neighbors' in bayes_results_knn.columns:\n",
    "    bayes_results_knn['K'] = bayes_results_knn['param_knn__n_neighbors'].astype(int)\n",
    "else:\n",
    "    raise KeyError(\"BayesSearchCV results do not include 'param_knn__n_neighbors'.\")\n",
    "\n",
    "for K in sorted(bayes_results_knn['K'].unique()):\n",
    "    df_k = bayes_results_knn[bayes_results_knn['K'] == K]\n",
    "    if not df_k.empty:\n",
    "        # Maximize neg RMSE (i.e., minimize RMSE)\n",
    "        idx = df_k['mean_test_neg_root_mean_squared_error'].idxmax()\n",
    "        best_row = df_k.loc[idx]\n",
    "\n",
    "        best_rmse = -best_row['mean_test_neg_root_mean_squared_error']\n",
    "        std_rmse = abs(best_row['std_test_neg_root_mean_squared_error'])  # std unaffected by sign\n",
    "        best_cv_r2 = best_row['mean_test_r2']\n",
    "        std_cv_r2 = best_row['std_test_r2']\n",
    "\n",
    "        # Capture the parameters for reporting\n",
    "        best_params = {\n",
    "            k.replace('param_', ''): best_row[k]\n",
    "            for k in df_k.columns if k.startswith('param_')\n",
    "        }\n",
    "\n",
    "        print(f\"K={K:>3d} | Best CV RMSE: {best_rmse:.4f} | R²: {best_cv_r2:.4f} | \"\n",
    "              f\"weights={best_params.get('knn__weights')}, p={best_params.get('knn__p')}, \"\n",
    "              f\"alg={best_params.get('knn__algorithm')}, scaler={best_params.get('scaler')}\")\n",
    "\n",
    "        cv_summary_per_k.append({\n",
    "            'K': K,\n",
    "            'best_cv_rmse': best_rmse,\n",
    "            'std_cv_rmse': std_rmse,\n",
    "            'best_cv_r2': best_cv_r2,\n",
    "            'std_cv_r2': std_cv_r2,\n",
    "            'best_params': best_params\n",
    "        })\n",
    "\n",
    "cv_knn_df = pd.DataFrame(cv_summary_per_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: left;\">\n",
    "Plot: Best CV RMSE & its STD vs K\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e40bf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- FONT SIZE METRICS ----\n",
    "tick_fontsize = 12\n",
    "axis_labelsize = 15\n",
    "legend_fontsize = 12\n",
    "\n",
    "# ---- GLOBAL FONT FAMILY: Times New Roman ----\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['mathtext.fontset'] = 'custom'\n",
    "plt.rcParams['mathtext.rm'] = 'Times New Roman'\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "# Sort by K for a clean x-axis\n",
    "cv_knn_df = cv_knn_df.sort_values('K').reset_index(drop=True)\n",
    "\n",
    "x = np.arange(len(cv_knn_df['K']))\n",
    "bar_width = 0.35\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(7, 3.5))\n",
    "\n",
    "# Blue bars: Best CV RMSE (left y-axis)\n",
    "bars1 = ax1.bar(\n",
    "    x - bar_width/2, \n",
    "    cv_knn_df['best_cv_rmse'], \n",
    "    bar_width, \n",
    "    color='#1976d2',\n",
    "    label='RMSE',\n",
    "    edgecolor='black',\n",
    "    linewidth=1,\n",
    "    zorder=3\n",
    ")\n",
    "ax1.set_xlabel('K (n_neighbors)', fontsize=axis_labelsize)\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(cv_knn_df['K'], fontsize=tick_fontsize, rotation=0)\n",
    "ax1.tick_params(axis='y', labelcolor='#1976d2', labelsize=tick_fontsize)\n",
    "ax1.grid(True, axis='y')\n",
    "\n",
    "# Magenta bars: STD of CV RMSE (right y-axis)\n",
    "ax2 = ax1.twinx()\n",
    "bars2 = ax2.bar(\n",
    "    x + bar_width/2, \n",
    "    cv_knn_df['std_cv_rmse'], \n",
    "    bar_width, \n",
    "    color='#d81b60',\n",
    "    label='Std. of RMSE',\n",
    "    edgecolor='black',\n",
    "    linewidth=1,\n",
    "    zorder=3\n",
    ")\n",
    "ax2.tick_params(axis='y', labelcolor='#d81b60', labelsize=tick_fontsize)\n",
    "ax2.grid(False)\n",
    "\n",
    "# Single legend\n",
    "handles = [\n",
    "    plt.Rectangle((0,0),1,1,color='#1976d2',ec='black',label='RMSE (dB)'),\n",
    "    plt.Rectangle((0,0),1,1,color='#d81b60',ec='black',label='Std. of RMSE (dB)')\n",
    "]\n",
    "ax1.legend(handles=handles, loc='upper right', fontsize=legend_fontsize)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('../../Comprehensive ML - Files & Plots etc/KNN_bestRMSE_&_STD_perK.png', dpi=2000, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: left;\">\n",
    "Plot: Best CV R² & its STD vs K\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de6d82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- FONT SIZE METRICS ----\n",
    "tick_fontsize = 12\n",
    "axis_labelsize = 15\n",
    "legend_fontsize = 12\n",
    "\n",
    "# ---- GLOBAL FONT FAMILY: Times New Roman ----\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['mathtext.fontset'] = 'custom'\n",
    "plt.rcParams['mathtext.rm'] = 'Times New Roman'\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "x = np.arange(len(cv_knn_df['K']))\n",
    "bar_width = 0.35\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(7, 3.5))\n",
    "\n",
    "# Cyan bars: Best CV R² (left y-axis)\n",
    "bars1 = ax1.bar(\n",
    "    x - bar_width/2, \n",
    "    cv_knn_df['best_cv_r2'], \n",
    "    bar_width, \n",
    "    color='#00bcd4',\n",
    "    edgecolor='black',\n",
    "    linewidth=1,\n",
    "    alpha=0.8,\n",
    "    label='R$^2$'\n",
    ")\n",
    "ax1.set_xlabel('K (n_neighbors)', fontsize=axis_labelsize)\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(cv_knn_df['K'], fontsize=tick_fontsize)\n",
    "ax1.tick_params(axis='y', labelcolor='#00bcd4', labelsize=tick_fontsize)\n",
    "ax1.tick_params(axis='x', labelsize=tick_fontsize)\n",
    "ax1.set_ylim(0, 1.01)\n",
    "ax1.grid(True, axis='y')\n",
    "\n",
    "# Green bars: STD of CV R² (right y-axis)\n",
    "ax2 = ax1.twinx()\n",
    "bars2 = ax2.bar(\n",
    "    x + bar_width/2, \n",
    "    cv_knn_df['std_cv_r2'], \n",
    "    bar_width, \n",
    "    color='#388e3c',\n",
    "    edgecolor='black',\n",
    "    linewidth=1,\n",
    "    alpha=0.8,\n",
    "    label='Std. of R$^2$'\n",
    ")\n",
    "ax2.tick_params(axis='y', labelcolor='#388e3c', labelsize=tick_fontsize)\n",
    "ax2.grid(False)\n",
    "\n",
    "# Combined Legend\n",
    "handles = [\n",
    "    plt.Rectangle((0,0),1,1,color='#00bcd4',ec='black',label='R$^2$'),\n",
    "    plt.Rectangle((0,0),1,1,color='#388e3c',ec='black',label='Std. of R$^2$')\n",
    "]\n",
    "ax1.legend(handles=handles, loc='upper right', fontsize=legend_fontsize)\n",
    "\n",
    "fig.tight_layout()\n",
    "# plt.savefig('../../Comprehensive ML - Files & Plots etc/KNN_bestR2_STD_perK.png', dpi=2000, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eca79ab",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: left;\">\n",
    "Train best KNN on full train set, evaluate on test, and save model\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc8bd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use built-in best_estimator_ (already refitted on full train data) and best_params_\n",
    "best_knn_model = bayes_cv_knn.best_estimator_\n",
    "best_knn_params = bayes_cv_knn.best_params_\n",
    "print(\"Best KNN Parameters Found:\", best_knn_params)\n",
    "\n",
    "print(\"\\nUsing best KNN model from BayesSearchCV (already trained on all data)...\")\n",
    "\n",
    "y_train_pred = best_knn_model.predict(X_train)\n",
    "y_test_pred  = best_knn_model.predict(X_test)\n",
    "\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse  = mean_squared_error(y_test, y_test_pred)\n",
    "train_r2  = r2_score(y_train, y_train_pred)\n",
    "test_r2   = r2_score(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_mape = mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "test_median_ae = median_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Metric': [\n",
    "        'Training Loss (MSE)', 'Test Loss (MSE)', 'Test RMSE',\n",
    "        'R² Score (Train)', 'R² Score (Test)', 'Test MAPE (%)', 'Test Median AE'\n",
    "    ],\n",
    "    'Value': [\n",
    "        train_mse, test_mse, test_rmse, train_r2, test_r2,\n",
    "        test_mape * 100, test_median_ae\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nModel Evaluation Metrics:\")\n",
    "display(results)\n",
    "\n",
    "# Ensure the directory exists and save the trained KNN model\n",
    "models_dir = '../Models'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(models_dir, 'knn_final_model.pkl'), 'wb') as f:\n",
    "    pickle.dump(best_knn_model, f)\n",
    "\n",
    "print(\"Trained KNN model saved to ../Models/knn_final_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ddaa8c",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: left;\">\n",
    "Learning curve\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655a55aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (7, 3)\n",
    "path = '../../Comprehensive ML - Files & Plots etc/'\n",
    "\n",
    "# Learning Curve\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    best_knn_model, X_train, y_train, cv=5, n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "    scoring='neg_root_mean_squared_error'\n",
    ")\n",
    "\n",
    "train_rmse = -train_scores.mean(1)\n",
    "test_rmse  = -test_scores.mean(1)\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "plt.plot(train_sizes, train_rmse, 'o-', label='Train RMSE')\n",
    "plt.plot(train_sizes, test_rmse,  'o-', label='Test RMSE')\n",
    "plt.xlabel('Training Size')\n",
    "plt.ylabel('RMSE (dB)')\n",
    "plt.title('KNN Learning Curve')\n",
    "plt.legend()\n",
    "# plt.savefig(f'{path}KNN_learning_curve.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac59f08",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: left;\">\n",
    "Residuals \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac436a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = best_knn_model.predict(X_test)\n",
    "residuals = y_test - y_test_pred\n",
    "\n",
    "plt.figure(figsize=(7, 3))\n",
    "plt.scatter(y_test_pred, residuals, alpha=0.5)\n",
    "plt.axhline(0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted PL (dB)')\n",
    "plt.ylabel('Residuals (dB)')\n",
    "plt.title('KNN Residuals')\n",
    "# plt.savefig(f'{path}KNN_residuals.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ace330",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: left;\">\n",
    "Physics consistency: PL vs log10(distance)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218668ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = df_test['distance'].values\n",
    "log_dist = np.log10(dist + 1e-6)  # guard against log(0)\n",
    "\n",
    "slope, intercept, r_value, _, _ = linregress(log_dist, y_test_pred)\n",
    "\n",
    "plt.figure(figsize=(7, 3))\n",
    "plt.scatter(log_dist, y_test_pred, alpha=0.5)\n",
    "plt.plot(log_dist, intercept + slope * log_dist, 'r--', \n",
    "         label=f'n ~ {slope:.2f}, R²={r_value**2:.2f}')\n",
    "plt.xlabel('log10(Distance)')\n",
    "plt.ylabel('Predicted PL (dB)')\n",
    "plt.title('KNN PL vs. log(Distance)')\n",
    "plt.legend()\n",
    "# plt.savefig(f'{path}KNN_physics_consistency.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63ba2d4",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: left;\">\n",
    "Predicted vs Real\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e97f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 3))\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.5)\n",
    "min_val = min(y_test.min(), y_test_pred.min())\n",
    "max_val = max(y_test.max(), y_test_pred.max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'r--')\n",
    "plt.xlabel('Real PL (dB)')\n",
    "plt.ylabel('Predicted PL (dB)')\n",
    "plt.title('KNN Predicted vs. Real')\n",
    "# plt.savefig(f'{path}KNN_pred_vs_real.png', dpi=300)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml001",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
