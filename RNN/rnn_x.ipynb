{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "427f33c1",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: left;\">\n",
    "Recurrent Neural Networks (RNN) Regression\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d5f989",
   "metadata": {},
   "source": [
    "#### Purpose and evaluation protocol\n",
    "\n",
    "This notebook implements a time-aware RNN pipeline for path loss prediction using fixed-length sequences. The evaluation design follows strict temporal separation to avoid leakage.\n",
    "\n",
    "Key principles:\n",
    "- Train/test split is time-ordered (train window precedes test window).\n",
    "- Model selection is done via time-aware cross-validation on the training window only.\n",
    "- Feature scaling is fit on the training window and applied to validation/test.\n",
    "- Sequences are built within folds to avoid leakage across time boundaries.\n",
    "- The held-out test window is used once for final reporting.\n",
    "\n",
    "Metrics reported: MSE, MAE, RMSE, R2, MAPE, Median AE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c367ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for data manipulation, visualization, and modeling\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, BatchNormalization, Dropout, LeakyReLU, SimpleRNN\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from sklearn.metrics import (mean_squared_error, r2_score, mean_absolute_percentage_error, median_absolute_error)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# Set seed for reproducibility\n",
    "GLOBAL_SEED = 50\n",
    "np.random.seed(GLOBAL_SEED)                      # Seed for NumPy\n",
    "tf.random.set_seed(GLOBAL_SEED)                  # Seed for TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1854f3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-aware data load (from Data Preparation.ipynb outputs)\n",
    "\n",
    "base_path = '../../Comprehensive ML - Files & Plots etc'\n",
    "\n",
    "df_train = pd.read_csv(f\"{base_path}/train.csv\", parse_dates=['time'])\n",
    "df_test  = pd.read_csv(f\"{base_path}/test.csv\", parse_dates=['time'])\n",
    "\n",
    "fold_assignments = np.load(f\"{base_path}/train_folds.npy\")\n",
    "fold_assignments = np.asarray(fold_assignments).ravel()\n",
    "\n",
    "if len(fold_assignments) != len(df_train):\n",
    "    raise ValueError(\"fold_assignments length does not match df_train rows.\")\n",
    "\n",
    "feature_columns = [\n",
    "    'distance',\n",
    "    'frequency',\n",
    "    'c_walls',\n",
    "    'w_walls',\n",
    "    'co2',\n",
    "    'humidity',\n",
    "    'pm25',\n",
    "    'pressure',\n",
    "    'temperature',\n",
    "    'snr'\n",
    "]\n",
    "target_column = 'PL'\n",
    "\n",
    "missing_train = set(feature_columns + [target_column]) - set(df_train.columns)\n",
    "missing_test  = set(feature_columns + [target_column]) - set(df_test.columns)\n",
    "if missing_train:\n",
    "    raise ValueError(f\"Missing columns in train.csv: {missing_train}\")\n",
    "if missing_test:\n",
    "    raise ValueError(f\"Missing columns in test.csv: {missing_test}\")\n",
    "\n",
    "# Raw features (NO global scaling here)\n",
    "X_train_all = df_train[feature_columns].to_numpy()\n",
    "X_test_all  = df_test[feature_columns].to_numpy()\n",
    "PL_train_all = df_train[target_column].to_numpy()\n",
    "PL_test_all  = df_test[target_column].to_numpy()\n",
    "\n",
    "# Time-aware folds\n",
    "ps = PredefinedSplit(fold_assignments)\n",
    "\n",
    "# Hold out the most recent training fold for final validation (raw split)\n",
    "fold_ids = np.unique(fold_assignments)\n",
    "fold_ids = fold_ids[fold_ids >= 0]\n",
    "if fold_ids.size == 0:\n",
    "    raise ValueError(\"fold_assignments must contain at least one non-negative fold id.\")\n",
    "\n",
    "val_fold = fold_ids.max()\n",
    "val_mask = fold_assignments == val_fold\n",
    "\n",
    "X_train_time_raw = X_train_all[~val_mask]\n",
    "y_train_time     = PL_train_all[~val_mask]\n",
    "X_val_time_raw   = X_train_all[val_mask]\n",
    "y_val_time       = PL_train_all[val_mask]\n",
    "\n",
    "print(f\"Train: {len(df_train)} rows, Test: {len(df_test)} rows\")\n",
    "print(f\"Train window: {df_train.time.min()} -> {df_train.time.max()}\")\n",
    "print(f\"Test window:  {df_test.time.min()} -> {df_test.time.max()}\")\n",
    "print(f\"Validation fold: {val_fold} (rows: {val_mask.sum()})\")\n",
    "print(\"Time-based split prepared (scaling will be fit inside folds and on the train window only).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b368a40f",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: left;\">\n",
    "Model Definition\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11192bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence settings\n",
    "SEQ_LEN = 10\n",
    "RNN_UNITS_LIST = [32, 64, 128]  \n",
    "\n",
    "def make_sequences(X, y, seq_len):\n",
    "    if len(X) < seq_len:\n",
    "        raise ValueError(f\"Not enough rows to build sequences: {len(X)} < SEQ_LEN={seq_len}\")\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - seq_len + 1):\n",
    "        Xs.append(X[i:i + seq_len])\n",
    "        ys.append(y[i + seq_len - 1])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "def build_sequences_by_fold_scaled(X_scaled, y, fold_assignments_subset, seq_len):\n",
    "    X_list, y_list = [], []\n",
    "    unique_folds = np.unique(fold_assignments_subset)\n",
    "    for fid in unique_folds:\n",
    "        idx = np.flatnonzero(fold_assignments_subset == fid)\n",
    "        if idx.size < seq_len:\n",
    "            raise ValueError(f\"Fold {fid} has {idx.size} rows; SEQ_LEN={seq_len}\")\n",
    "        X_seq, y_seq = make_sequences(X_scaled[idx], y[idx], seq_len)\n",
    "        X_list.append(X_seq)\n",
    "        y_list.append(y_seq)\n",
    "    if not X_list:\n",
    "        raise ValueError(\"No sequences were created; check SEQ_LEN or data size.\")\n",
    "    return np.concatenate(X_list), np.concatenate(y_list)\n",
    "\n",
    "def create_rnn_model(layer_units, seq_len, n_features, \n",
    "                     rnn_units=64, \n",
    "                     l2_reg=1e-4, \n",
    "                     dropout_rate=0.1, \n",
    "                     negative_slope=0.1):\n",
    "    '''\n",
    "    Creates a one-way RNN model for regression with configurable dense architecture.\n",
    "    \n",
    "    Arguments:\n",
    "        layer_units    : list of integers (e.g., [64, 32]) specifying \n",
    "                         the number of neurons in each dense layer\n",
    "        seq_len        : int, sequence length\n",
    "        n_features     : int, number of features per time step\n",
    "        rnn_units      : int, number of units in the SimpleRNN layer\n",
    "        l2_reg         : float, L2 regularization factor\n",
    "        dropout_rate   : float, dropout rate\n",
    "        negative_slope : float, negative slope for LeakyReLU\n",
    "    Returns:\n",
    "        model          : Compiled Keras Sequential model\n",
    "    '''\n",
    "    model = Sequential()\n",
    "\n",
    "    # Explicit input layer\n",
    "    model.add(Input(shape=(seq_len, n_features)))\n",
    "\n",
    "    # One-way RNN layer\n",
    "    model.add(SimpleRNN(rnn_units, activation='tanh', kernel_regularizer=l2(l2_reg)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Dense layers based on the list of units\n",
    "    for units in layer_units:\n",
    "        model.add(Dense(units, kernel_regularizer=l2(l2_reg)))\n",
    "        model.add(LeakyReLU(negative_slope=negative_slope))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Output layer for regression\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6c7f1b",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: left;\">\n",
    "Architecture Grid\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d209deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_architectures(rnn_units_list):\n",
    "    archs = []\n",
    "\n",
    "    for rnn_units in rnn_units_list:\n",
    "        # 1-layer\n",
    "        for h1 in [8, 16, 32, 64, 128]:\n",
    "            archs.append({\"name\": f\"RNN{rnn_units}_L1_{h1}\", \"units\": [h1], \"rnn_units\": rnn_units})\n",
    "\n",
    "        # 2-layer funnels\n",
    "        for h1, h2 in [(32, 16), (64, 32), (128, 64), (64, 16), (128, 32)]:\n",
    "            archs.append({\"name\": f\"RNN{rnn_units}_L2_{h1}_{h2}\", \"units\": [h1, h2], \"rnn_units\": rnn_units})\n",
    "\n",
    "        # 3-layer funnels\n",
    "        for h1, h2, h3 in [(32, 16, 8), (64, 32, 16), (128, 64, 32), (64, 16, 8), (128, 32, 16)]:\n",
    "            archs.append({\"name\": f\"RNN{rnn_units}_L3_{h1}_{h2}_{h3}\", \"units\": [h1, h2, h3], \"rnn_units\": rnn_units})\n",
    "\n",
    "        # Mauricio-style anchor\n",
    "        archs.append({\"name\": f\"RNN{rnn_units}_L3_20_10_5\", \"units\": [20, 10, 5], \"rnn_units\": rnn_units})\n",
    "\n",
    "    return archs\n",
    "\n",
    "architectures = build_architectures(RNN_UNITS_LIST)\n",
    "len(architectures), architectures[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb085a1f",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: left;\">\n",
    "Time-Aware Cross-Validation (Model Selection)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329c9f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# Time-aware cross-validation for each architecture\n",
    "kfold_results = []\n",
    "\n",
    "n_splits = ps.get_n_splits()\n",
    "\n",
    "for arch in architectures:\n",
    "    print(f\"Performing {n_splits}-Fold CV for Architecture: {arch['name']}\")\n",
    "    fold_metrics = []\n",
    "    \n",
    "    for fold_num, (train_idx, val_idx) in enumerate(ps.split(X_train_all), start=1):\n",
    "        print(f\"  Fold {fold_num}/{n_splits}...\")\n",
    "\n",
    "        train_idx = np.sort(train_idx)\n",
    "        val_idx = np.sort(val_idx)\n",
    "\n",
    "        # RAW splits\n",
    "        X_train_fold_raw = X_train_all[train_idx]\n",
    "        y_train_fold = PL_train_all[train_idx]\n",
    "        folds_train = fold_assignments[train_idx]\n",
    "\n",
    "        X_val_fold_raw = X_train_all[val_idx]\n",
    "        y_val_fold = PL_train_all[val_idx]\n",
    "        folds_val = fold_assignments[val_idx]\n",
    "\n",
    "        # Fold-wise scaling (fit only on current train fold set)\n",
    "        scaler_fold = StandardScaler()\n",
    "        X_train_fold_scaled = scaler_fold.fit_transform(X_train_fold_raw)\n",
    "        X_val_fold_scaled = scaler_fold.transform(X_val_fold_raw)\n",
    "\n",
    "        # Build sequences within each fold\n",
    "        X_train_seq, y_train_seq = build_sequences_by_fold_scaled(\n",
    "            X_train_fold_scaled, y_train_fold, folds_train, SEQ_LEN\n",
    "        )\n",
    "        X_val_seq, y_val_seq = build_sequences_by_fold_scaled(\n",
    "            X_val_fold_scaled, y_val_fold, folds_val, SEQ_LEN\n",
    "        )\n",
    "        \n",
    "        # Build model\n",
    "        model_cv = create_rnn_model(\n",
    "            layer_units=arch['units'],\n",
    "            seq_len=SEQ_LEN,\n",
    "            n_features=X_train_fold_scaled.shape[1],\n",
    "            rnn_units=arch['rnn_units'],\n",
    "            l2_reg=0.001,\n",
    "            dropout_rate=0.3,\n",
    "            negative_slope=0.1\n",
    "        )\n",
    "        \n",
    "        # Define callbacks\n",
    "        early_stop_cv = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "        reduce_lr_cv = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=0)\n",
    "        \n",
    "        # Train\n",
    "        model_cv.fit(\n",
    "            X_train_seq,\n",
    "            y_train_seq,\n",
    "            validation_data=(X_val_seq, y_val_seq),\n",
    "            epochs=100,\n",
    "            batch_size=128,\n",
    "            verbose=0,\n",
    "            callbacks=[early_stop_cv, reduce_lr_cv],\n",
    "            shuffle=False\n",
    "        )\n",
    "        \n",
    "        # Evaluate on the validation sequences\n",
    "        val_loss_cv, val_mae_cv = model_cv.evaluate(X_val_seq, y_val_seq, verbose=0)\n",
    "        val_pred = model_cv.predict(X_val_seq).flatten()\n",
    "        \n",
    "        # Compute metrics\n",
    "        rmse_cv = np.sqrt(mean_squared_error(y_val_seq, val_pred))\n",
    "        r2_cv = r2_score(y_val_seq, val_pred)\n",
    "        mape_cv = mean_absolute_percentage_error(y_val_seq, val_pred) * 100\n",
    "        median_ae_cv = median_absolute_error(y_val_seq, val_pred)\n",
    "        \n",
    "        fold_metrics.append({\n",
    "            'Fold': fold_num,\n",
    "            'Val MSE': val_loss_cv,\n",
    "            'Val MAE': val_mae_cv,\n",
    "            'Val RMSE': rmse_cv,\n",
    "            'R2 Score': r2_cv,\n",
    "            'Val MAPE (%)': mape_cv,\n",
    "            'Val Median AE': median_ae_cv\n",
    "        })\n",
    "        \n",
    "        print(f\" Fold {fold_num} Metrics - Val MSE: {val_loss_cv:.4f} | Val RMSE: {rmse_cv:.4f} | R2: {r2_cv:.4f} | MAPE: {mape_cv:.2f}%\")\n",
    "    \n",
    "    # After CV loop, summarize\n",
    "    arch_cv_df = pd.DataFrame(fold_metrics)\n",
    "    arch_cv_mean = arch_cv_df.mean(numeric_only=True)\n",
    "    arch_cv_std = arch_cv_df.std(numeric_only=True)\n",
    "    \n",
    "    kfold_results.append({\n",
    "        'Architecture': arch['name'],\n",
    "        'Hidden Layers': str(arch['units']),\n",
    "        'RNN Units': arch['rnn_units'],\n",
    "        'Mean Val MSE': arch_cv_mean['Val MSE'],\n",
    "        'Std Val MSE': arch_cv_std['Val MSE'],\n",
    "        'Mean Val MAE': arch_cv_mean['Val MAE'],\n",
    "        'Std Val MAE': arch_cv_std['Val MAE'],\n",
    "        'Mean Val RMSE': arch_cv_mean['Val RMSE'],\n",
    "        'Std Val RMSE': arch_cv_std['Val RMSE'],\n",
    "        'Mean R2': arch_cv_mean['R2 Score'],\n",
    "        'Std R2': arch_cv_std['R2 Score'],\n",
    "        'Mean Val MAPE (%)': arch_cv_mean['Val MAPE (%)'],\n",
    "        'Std Val MAPE (%)': arch_cv_std['Val MAPE (%)'],\n",
    "        'Mean Val MedAE': arch_cv_mean['Val Median AE'],\n",
    "        'Std Val MedAE': arch_cv_std['Val Median AE']\n",
    "    })\n",
    "\n",
    "# Display aggregated CV results for all architectures\n",
    "kfold_results_df = pd.DataFrame(kfold_results)\n",
    "kfold_results_df_sorted = kfold_results_df.sort_values(by='Mean Val RMSE', ascending=True)\n",
    "print(\"\\nTime-aware CV summary (sorted by Mean Val RMSE):\")\n",
    "kfold_results_df_sorted.head()\n",
    "\n",
    "# Save the results to a CSV file\n",
    "kfold_results_df_sorted.to_csv('Results/kfold_results_summary.csv', index=False)\n",
    "print(\"\\nCV results saved to kfold_results_summary.csv\")\n",
    "\n",
    "# Select the best architecture by CV\n",
    "best_arch_name = kfold_results_df_sorted.iloc[0]['Architecture']\n",
    "best_arch_units = next(a['units'] for a in architectures if a['name'] == best_arch_name)\n",
    "best_rnn_units = next(a['rnn_units'] for a in architectures if a['name'] == best_arch_name)\n",
    "print(f\"\\nSelected architecture: {best_arch_name} with layers {best_arch_units} and RNN units {best_rnn_units}\")\n",
    "\n",
    "t1 = time.time()\n",
    "print(f\"\\nRNN CV complete in {(t1 - t0)/60:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab3f7bf",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: left;\">\n",
    "Full Training and Test Evaluation\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b84dd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = time.time()\n",
    "\n",
    "# Leak-free scaling for the final train/val/test stage\n",
    "X_train_time_raw = X_train_all[~val_mask]\n",
    "X_val_time_raw   = X_train_all[val_mask]\n",
    "\n",
    "scaler_final = StandardScaler()\n",
    "X_train_time_scaled = scaler_final.fit_transform(X_train_time_raw)   # fit on train window only\n",
    "X_val_time_scaled   = scaler_final.transform(X_val_time_raw)\n",
    "X_test_all_scaled   = scaler_final.transform(X_test_all)             # transform test with same scaler\n",
    "\n",
    "# Build sequences within train and validation folds\n",
    "folds_train_time = fold_assignments[~val_mask]\n",
    "folds_val_time   = fold_assignments[val_mask]\n",
    "\n",
    "X_train_seq, y_train_seq = build_sequences_by_fold_scaled(\n",
    "    X_train_time_scaled, y_train_time, folds_train_time, SEQ_LEN\n",
    ")\n",
    "X_val_seq, y_val_seq = build_sequences_by_fold_scaled(\n",
    "    X_val_time_scaled, y_val_time, folds_val_time, SEQ_LEN\n",
    ")\n",
    "\n",
    "if len(X_test_all_scaled) < SEQ_LEN:\n",
    "    raise ValueError(f\"Test set too small for SEQ_LEN={SEQ_LEN}\")\n",
    "X_test_seq, PL_test_seq = make_sequences(X_test_all_scaled, PL_test_all, SEQ_LEN)\n",
    "\n",
    "# Train the selected architecture on the training window\n",
    "final_model = create_rnn_model(\n",
    "    layer_units=best_arch_units,\n",
    "    seq_len=SEQ_LEN,\n",
    "    n_features=X_train_time_scaled.shape[1],\n",
    "    rnn_units=best_rnn_units,\n",
    "    l2_reg=0.001,\n",
    "    dropout_rate=0.3,\n",
    "    negative_slope=0.1\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6, verbose=0)\n",
    "\n",
    "history_final = final_model.fit(\n",
    "    X_train_seq,\n",
    "    y_train_seq,\n",
    "    validation_data=(X_val_seq, y_val_seq),\n",
    "    epochs=500,\n",
    "    batch_size=128,\n",
    "    verbose=0,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Evaluate on the held-out test set\n",
    "final_test_mse, final_test_mae = final_model.evaluate(X_test_seq, PL_test_seq, verbose=0)\n",
    "final_pred = final_model.predict(X_test_seq).flatten()\n",
    "\n",
    "final_test_rmse = np.sqrt(mean_squared_error(PL_test_seq, final_pred))\n",
    "final_test_r2 = r2_score(PL_test_seq, final_pred)\n",
    "final_test_mape = mean_absolute_percentage_error(PL_test_seq, final_pred) * 100\n",
    "final_test_median_ae = median_absolute_error(PL_test_seq, final_pred)\n",
    "\n",
    "final_results_df = pd.DataFrame([\n",
    "    {\n",
    "        'Architecture': best_arch_name,\n",
    "        'Hidden Layers': str(best_arch_units),\n",
    "        'RNN Units': best_rnn_units,\n",
    "        'SEQ_LEN': SEQ_LEN,\n",
    "        'Test MSE': final_test_mse,\n",
    "        'Test MAE': final_test_mae,\n",
    "        'Test RMSE': final_test_rmse,\n",
    "        'R2 Score': final_test_r2,\n",
    "        'Test MAPE (%)': final_test_mape,\n",
    "        'Test Median AE': final_test_median_ae\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"Final model evaluation on held-out test set:\")\n",
    "display(final_results_df)\n",
    "\n",
    "# --- Save single PKL bundle ---\n",
    "model_path = \"../Models/rnn_final_model.pkl\"\n",
    "os.makedirs(\"../Models\", exist_ok=True)\n",
    "rnn_bundle = {\n",
    "    \"best_arch_name\": best_arch_name,\n",
    "    \"best_arch_units\": best_arch_units,\n",
    "    \"seq_len\": int(SEQ_LEN),\n",
    "    \"rnn_units\": int(best_rnn_units),\n",
    "    \"n_features\": int(X_train_all.shape[1]),\n",
    "    \"feature_columns\": feature_columns,\n",
    "    \"target_column\": target_column,\n",
    "    \"model_params\": {\"l2_reg\": 0.001, \"dropout_rate\": 0.3, \"negative_slope\": 0.1},\n",
    "    \"model_weights\": final_model.get_weights(),\n",
    "    \"scaler\": scaler_final,\n",
    "}\n",
    "with open(model_path, \"wb\") as f:\n",
    "    pickle.dump(rnn_bundle, f)\n",
    "\n",
    "print(f\"Saved RNN model bundle to {model_path}\")\n",
    "\n",
    "t3 = time.time()\n",
    "print(f\"\\nTask complete in {(t3 - t2)/60:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3eeb7b2",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: left;\">\n",
    "RNN Architecture Performance Analysis\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e96a168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import ast\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.colors import qualitative\n",
    "\n",
    "# Load the DataFrame\n",
    "model_results_df = pd.read_csv(\"Results/kfold_results_summary.csv\")\n",
    "model_results_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0cf0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to sum hidden layers\n",
    "def sum_hidden_layers(hidden_layers_str):\n",
    "    # Convert string representation of list to an actual list\n",
    "    hidden_layers = ast.literal_eval(hidden_layers_str)\n",
    "    # Calculate and return the sum\n",
    "    return sum(hidden_layers)\n",
    "    \n",
    "# Define a function to count the number of hidden layers\n",
    "def count_hidden_layers(hidden_layers_str):\n",
    "    # Convert string representation of list to an actual list\n",
    "    hidden_layers = ast.literal_eval(hidden_layers_str)\n",
    "    # Return the number of layers\n",
    "    return len(hidden_layers)\n",
    "\n",
    "# Apply the function to create 'Total Nodes' column\n",
    "model_results_df['Total Nodes'] = model_results_df['Hidden Layers'].apply(sum_hidden_layers)\n",
    "\n",
    "# Apply the function to create 'Number of Layers' column\n",
    "model_results_df['Number of Layers'] = model_results_df['Hidden Layers'].apply(count_hidden_layers)\n",
    "\n",
    "# Rename columns (requested names)\n",
    "model_results_df.rename(\n",
    "    columns={\n",
    "        \"Mean Val RMSE\": \"Test RMSE\",\n",
    "        \"Mean R2\": \"R2 Score\",\n",
    "        \"Std Val RMSE\": \"Std RMSE\"\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "model_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b92b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by Test RMSE\n",
    "model_results_df_sorted = model_results_df.sort_values(by='Test RMSE', ascending=True)\n",
    "\n",
    "# Prepare customdata\n",
    "custom_cols = ['R2 Score', 'Number of Layers', 'Hidden Layers']\n",
    "customdata = model_results_df_sorted[custom_cols].values\n",
    "\n",
    "# Auto color mapping for any number of layers\n",
    "layers = sorted(model_results_df_sorted['Number of Layers'].unique())\n",
    "palette = qualitative.Set2\n",
    "color_map = {n: palette[i % len(palette)] for i, n in enumerate(layers)}\n",
    "colors = model_results_df_sorted['Number of Layers'].map(color_map)\n",
    "\n",
    "# Figure with secondary y-axis\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "# Test RMSE bars (colored by layer count) + black borders, no legend entry\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=model_results_df_sorted['Architecture'],\n",
    "        y=model_results_df_sorted['Test RMSE'],\n",
    "        name='Test RMSE',\n",
    "        marker=dict(color=colors, line=dict(color='black', width=1)),\n",
    "        text=model_results_df_sorted['Total Nodes'],\n",
    "        hoverinfo='none',\n",
    "        hovertemplate=(\n",
    "            '<b>Architecture:</b> %{x}<br>'\n",
    "            '<b>Test RMSE:</b> %{y:.2f}<br>'\n",
    "            '<b>R2 Score:</b> %{customdata[0]:.4f}<br>'\n",
    "            '<b>Total Nodes:</b> %{text}<br>'\n",
    "            '<b>Number of Layers:</b> %{customdata[1]}<br>'\n",
    "            '<b>Hidden Layers:</b> %{customdata[2]}<br>'\n",
    "            '<extra></extra>'\n",
    "        ),\n",
    "        customdata=customdata,\n",
    "        showlegend=False,\n",
    "    ),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "# Legend entry for Test RMSE (black box)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[None],\n",
    "        y=[None],\n",
    "        mode='markers',\n",
    "        marker=dict(size=10, color='black', symbol='square-open', line=dict(color='black', width=1)),\n",
    "        name='Test RMSE',\n",
    "        showlegend=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Auto legend entries for each layer count\n",
    "for n in layers:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[None],\n",
    "            y=[None],\n",
    "            mode='markers',\n",
    "            marker=dict(size=10, color=color_map[n]),\n",
    "            name=f'{n} Hidden Layer{\"s\" if n != 1 else \"\"}',\n",
    "            showlegend=True,\n",
    "        )\n",
    "    )\n",
    "\n",
    "# R2 line on secondary axis (non-interactive)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=model_results_df_sorted['Architecture'],\n",
    "        y=model_results_df_sorted['R2 Score'],\n",
    "        name='R2 Score',\n",
    "        mode='lines+markers',\n",
    "        line=dict(color='red', width=2),\n",
    "        marker=dict(size=8),\n",
    "        hoverinfo='skip',\n",
    "    ),\n",
    "    secondary_y=True,\n",
    ")\n",
    "\n",
    "# Axes + layout\n",
    "fig.update_xaxes(\n",
    "    title_text='Architecture',\n",
    "    tickmode='array',\n",
    "    tickvals=model_results_df_sorted['Architecture'],\n",
    "    ticktext=model_results_df_sorted['Architecture'],\n",
    "    tickangle=-45,\n",
    ")\n",
    "fig.update_yaxes(title_text='Test RMSE', secondary_y=False, color='blue')\n",
    "fig.update_yaxes(title_text='R2 Score', secondary_y=True, color='red')\n",
    "fig.update_layout(\n",
    "    title=dict(\n",
    "        text='Interactive Test RMSE and R2 Score for RNN Architectures',\n",
    "        x=0.5,\n",
    "        xanchor='center',\n",
    "    ),\n",
    "    barmode='group',\n",
    "    legend=dict(\n",
    "        orientation='h',\n",
    "        yanchor='bottom',\n",
    "        y=1.1,\n",
    "        xanchor='center',\n",
    "        x=0.5,\n",
    "        bgcolor='rgba(255,255,255,0.8)',\n",
    "    ),\n",
    "    hovermode='x unified',\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478ad072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- FONT SIZES ----\n",
    "tick_fontsize = 12\n",
    "axis_labelsize = 15\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "model_results_df_filtered_sorted = model_results_df_sorted.sort_values(by=\"Total Nodes\", ascending=True)\n",
    "\n",
    "x = np.arange(len(model_results_df_filtered_sorted))\n",
    "bar_width = 0.35\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10, 4.5))\n",
    "\n",
    "rmse_color = \"#1976d2\"\n",
    "std_color  = \"#d81b60\"\n",
    "\n",
    "ax1.bar(x - bar_width/2, model_results_df_filtered_sorted[\"Test RMSE\"], bar_width,\n",
    "        color=rmse_color, edgecolor=\"black\", linewidth=1, zorder=3)\n",
    "\n",
    "ax1.set_xlabel(\"RNN Architecture\", fontsize=axis_labelsize)\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(model_results_df_filtered_sorted[\"Hidden Layers\"], rotation=45, ha=\"right\", fontsize=tick_fontsize)\n",
    "\n",
    "ax1.set_ylabel(\"CV RMSE (dB)\", fontsize=axis_labelsize)\n",
    "ax1.tick_params(axis=\"y\", labelcolor=rmse_color, labelsize=tick_fontsize)\n",
    "ax1.grid(True, axis=\"y\")\n",
    "ax1.set_ylim(0, model_results_df_filtered_sorted[\"Test RMSE\"].max() * 1.12)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.bar(x + bar_width/2, model_results_df_filtered_sorted[\"Std RMSE\"], bar_width,\n",
    "        color=std_color, edgecolor=\"black\", linewidth=1, zorder=3)\n",
    "\n",
    "ax2.set_ylabel(\"Std RMSE (dB)\", fontsize=axis_labelsize)\n",
    "ax2.tick_params(axis=\"y\", labelcolor=std_color, labelsize=tick_fontsize)\n",
    "ax2.grid(False)\n",
    "\n",
    "# Std RMSE axis\n",
    "std = model_results_df_filtered_sorted[\"Std RMSE\"].astype(float).to_numpy()\n",
    "std_min, std_max = float(std.min()), float(std.max())\n",
    "pad = 0.05 * (std_max - std_min) if std_max > std_min else 0.05\n",
    "std_low, std_high = max(0.0, std_min - pad), std_max + pad\n",
    "\n",
    "ax2.set_ylim(std_low, std_high)\n",
    "ax2.set_yticks(np.round(np.linspace(std_low, std_high, 6), 2))  # ~6 ticks only\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"../../Comprehensive ML - Files & Plots etc/RNN_RMSE_STD_filtered.png\", dpi=2000, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml001",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
