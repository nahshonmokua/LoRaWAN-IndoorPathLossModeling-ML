{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c956b622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for data manipulation and visualization\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "# Modeling: SVR + pipeline + CV + metrics\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import PredefinedSplit, learning_curve\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, r2_score, mean_absolute_percentage_error, median_absolute_error\n",
    ")\n",
    "\n",
    "# Bayesian optimization (same tool as RF/KNN)\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer, Real, Categorical\n",
    "\n",
    "# Utility\n",
    "from scipy.stats import linregress\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='skopt')\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f6a0161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pilot mode: using 50% of data (831813 train, 207953 test samples).\n",
      "\n",
      "Training samples: 831813, Test samples: 207953\n",
      "{0: 166263, 1: 166335, 2: 166227, 3: 166526, 4: 166462}\n",
      "\n",
      "Dataset loaded successfully (pilot configuration applied if enabled).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the standardized database directory\n",
    "base_path = '../../Comprehensive ML - Files & Plots etc'\n",
    "\n",
    "# Load train and test splits\n",
    "df_train = pd.read_csv(f\"{base_path}/train.csv\")\n",
    "df_test  = pd.read_csv(f\"{base_path}/test.csv\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# PILOT MODE: use only a subset of the data (e.g. first 20 percent)\n",
    "# This is useful for quick tests of the pipeline before running on\n",
    "# the full dataset.\n",
    "# -------------------------------------------------------------------\n",
    "PILOT_MODE     = True        # set to False when you want to use all data\n",
    "PILOT_FRACTION = 0.5        # 20 percent\n",
    "\n",
    "if PILOT_MODE:\n",
    "    n_train_pilot = int(len(df_train) * PILOT_FRACTION)\n",
    "    n_test_pilot  = int(len(df_test)  * PILOT_FRACTION)\n",
    "\n",
    "    # Take rows from index 0 up to the 20 percent cut\n",
    "    df_train = df_train.iloc[:n_train_pilot].copy()\n",
    "    df_test  = df_test.iloc[:n_test_pilot].copy()\n",
    "\n",
    "    print(f\"Pilot mode: using {PILOT_FRACTION*100:.0f}% of data \"\n",
    "          f\"({n_train_pilot} train, {n_test_pilot} test samples).\")\n",
    "else:\n",
    "    print(\"Full data mode: using all training and test samples.\")\n",
    "\n",
    "# Feature definition\n",
    "feature_names = [\n",
    "    'distance', 'frequency', 'c_walls', 'w_walls', 'co2', 'humidity', \n",
    "    'pm25', 'pressure', 'temperature', 'snr'\n",
    "]\n",
    "\n",
    "# Design matrices and targets (now possibly on the pilot subset)\n",
    "X_train = df_train[feature_names].values\n",
    "y_train = df_train['PL'].values\n",
    "X_test  = df_test[feature_names].values\n",
    "y_test  = df_test['PL'].values\n",
    "\n",
    "# (Should we need them for plotting)\n",
    "time_train = df_train['time'].values\n",
    "time_test  = df_test['time'].values\n",
    "\n",
    "# Load 5-fold assignments and trim to the (possibly) reduced train size\n",
    "fold_assignments = np.load(f\"{base_path}/train_folds.npy\")\n",
    "fold_assignments = fold_assignments[:X_train.shape[0]]\n",
    "\n",
    "print(f\"\\nTraining samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}\")\n",
    "unique, counts = np.unique(fold_assignments, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "print('\\nDataset loaded successfully (pilot configuration applied if enabled).\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1514dd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_svr_pipeline():\n",
    "    \"\"\"\n",
    "    (Scaler) -> SVR\n",
    "    - Scaling is fitted only on train folds inside CV for proper evaluation.\n",
    "    \"\"\"\n",
    "    return Pipeline(steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svr', SVR(\n",
    "            kernel='rbf',   # default; BayesSearchCV will tune kernel\n",
    "            cache_size=1000 # MB; increase a bit to speed up training\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "# SVR hyperparameter search space (compact but expressive)\n",
    "# Note: gamma is ignored for linear kernel; that's fine.\n",
    "search_spaces = {\n",
    "    'scaler': Categorical([\n",
    "        StandardScaler(),\n",
    "        RobustScaler(quantile_range=(10.0, 90.0))\n",
    "    ]),\n",
    "    'svr__kernel':  Categorical(['rbf', 'linear']),            # can add 'poly' if desired\n",
    "    'svr__C':       Real(1e-2, 1e3, prior='log-uniform'),\n",
    "    'svr__epsilon': Real(1e-3, 0.5, prior='log-uniform'),\n",
    "    'svr__gamma':   Real(1e-5, 1e1, prior='log-uniform')       # used by 'rbf'\n",
    "    # If you want polynomial kernel too, add:\n",
    "    # 'svr__degree': Integer(2, 4),\n",
    "    # 'svr__coef0':  Real(0.0, 1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbb0e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Bayesian optimization with 30 iterations and 5-fold cross-validation per candidate...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    }
   ],
   "source": [
    "# ---- Multi-metric scoring (same as RF/KNN) ----\n",
    "scoring = {\n",
    "    'neg_root_mean_squared_error': 'neg_root_mean_squared_error',\n",
    "    'r2': 'r2'\n",
    "}\n",
    "\n",
    "# ---- PredefinedSplit ----\n",
    "ps = PredefinedSplit(fold_assignments)\n",
    "\n",
    "# ---- Bayesian optimization ----\n",
    "bayes_cv_svr = BayesSearchCV(\n",
    "    estimator=create_svr_pipeline(),\n",
    "    search_spaces=search_spaces,\n",
    "    n_iter=30,                               # adjust for runtime\n",
    "    scoring=scoring,\n",
    "    refit='neg_root_mean_squared_error',     # choose best by RMSE\n",
    "    n_jobs=-1,\n",
    "    cv=ps,\n",
    "    random_state=42,\n",
    "    verbose=2,\n",
    "    n_points=1,\n",
    "    optimizer_kwargs={'n_initial_points': 12, 'acq_func': 'gp_hedge'}\n",
    ")\n",
    "\n",
    "print(f\"Starting Bayesian optimization with {bayes_cv_svr.n_iter} iterations \"\n",
    "      f\"and {ps.get_n_splits()}-fold cross-validation per candidate...\")\n",
    "\n",
    "bayes_cv_svr.fit(X_train, y_train)\n",
    "\n",
    "print(\"Bayesian optimization complete. Extracting results...\")\n",
    "\n",
    "# ---- Pull all tried configs/results into a dataframe ----\n",
    "bayes_results_svr = pd.DataFrame(bayes_cv_svr.cv_results_).copy()\n",
    "print(f\"Tried {bayes_results_svr.shape[0]} SVR configurations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3a5c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_summary_per_kernel = []\n",
    "if 'param_svr__kernel' not in bayes_results_svr.columns:\n",
    "    raise KeyError(\"BayesSearchCV results do not include 'param_svr__kernel'.\")\n",
    "\n",
    "for kernel in sorted(bayes_results_svr['param_svr__kernel'].dropna().astype(str).unique()):\n",
    "    df_k = bayes_results_svr[bayes_results_svr['param_svr__kernel'].astype(str) == kernel]\n",
    "    if not df_k.empty:\n",
    "        idx = df_k['mean_test_neg_root_mean_squared_error'].idxmax()  # maximize neg RMSE\n",
    "        row = df_k.loc[idx]\n",
    "        best_rmse = -row['mean_test_neg_root_mean_squared_error']\n",
    "        std_rmse  =  row['std_test_neg_root_mean_squared_error']\n",
    "        best_r2   =  row['mean_test_r2']\n",
    "        std_r2    =  row['std_test_r2']\n",
    "        best_params = {c.split('param_')[1]: row[c] for c in df_k.columns if c.startswith('param_')}\n",
    "        print(f\"Kernel={kernel:>6s} | Best CV RMSE: {best_rmse:.4f} | R²: {best_r2:.4f} | params: {best_params}\")\n",
    "        cv_summary_per_kernel.append({\n",
    "            'kernel': kernel,\n",
    "            'best_cv_rmse': best_rmse,\n",
    "            'std_cv_rmse': std_rmse,\n",
    "            'best_cv_r2': best_r2,\n",
    "            'std_cv_r2': std_r2,\n",
    "            'best_params': best_params\n",
    "        })\n",
    "\n",
    "cv_svr_df = pd.DataFrame(cv_summary_per_kernel).sort_values('kernel').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068021f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- FONT SIZE METRICS ----\n",
    "tick_fontsize = 12\n",
    "axis_labelsize = 15\n",
    "legend_fontsize = 12\n",
    "\n",
    "# ---- GLOBAL FONT FAMILY: Times New Roman ----\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['mathtext.fontset'] = 'custom'\n",
    "plt.rcParams['mathtext.rm'] = 'Times New Roman'\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "x = np.arange(len(cv_svr_df['kernel']))\n",
    "bar_width = 0.35\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(7, 3.5))\n",
    "\n",
    "# Blue bars: Best CV RMSE (left y-axis)\n",
    "bars1 = ax1.bar(\n",
    "    x - bar_width/2, \n",
    "    cv_svr_df['best_cv_rmse'], \n",
    "    bar_width, \n",
    "    color='#1976d2',\n",
    "    label='RMSE',\n",
    "    edgecolor='black',\n",
    "    linewidth=1,\n",
    "    zorder=3\n",
    ")\n",
    "ax1.set_xlabel('kernel', fontsize=axis_labelsize)\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(cv_svr_df['kernel'], fontsize=tick_fontsize)\n",
    "ax1.tick_params(axis='y', labelcolor='#1976d2', labelsize=tick_fontsize)\n",
    "ax1.grid(True, axis='y')\n",
    "\n",
    "# Magenta bars: STD of CV RMSE (right y-axis)\n",
    "ax2 = ax1.twinx()\n",
    "bars2 = ax2.bar(\n",
    "    x + bar_width/2, \n",
    "    cv_svr_df['std_cv_rmse'], \n",
    "    bar_width, \n",
    "    color='#d81b60',\n",
    "    label='Std. of RMSE',\n",
    "    edgecolor='black',\n",
    "    linewidth=1,\n",
    "    zorder=3\n",
    ")\n",
    "ax2.tick_params(axis='y', labelcolor='#d81b60', labelsize=tick_fontsize)\n",
    "ax2.grid(False)\n",
    "\n",
    "# Single legend\n",
    "handles = [\n",
    "    plt.Rectangle((0,0),1,1,color='#1976d2',ec='black',label='RMSE (dB)'),\n",
    "    plt.Rectangle((0,0),1,1,color='#d81b60',ec='black',label='Std. of RMSE (dB)')\n",
    "]\n",
    "ax1.legend(handles=handles, loc='upper right', fontsize=legend_fontsize)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('../../Comprehensive ML - Files & Plots etc/SVR_bestRMSE_&_STD_perKernel.png',\n",
    "            dpi=2000, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba10f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- FONT SIZE METRICS ----\n",
    "tick_fontsize = 12\n",
    "axis_labelsize = 15\n",
    "legend_fontsize = 12\n",
    "\n",
    "# ---- GLOBAL FONT FAMILY: Times New Roman ----\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['mathtext.fontset'] = 'custom'\n",
    "plt.rcParams['mathtext.rm'] = 'Times New Roman'\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "x = np.arange(len(cv_svr_df['kernel']))\n",
    "bar_width = 0.35\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(7, 3.5))\n",
    "\n",
    "# Cyan bars: Best CV R² (left y-axis)\n",
    "bars1 = ax1.bar(\n",
    "    x - bar_width/2, \n",
    "    cv_svr_df['best_cv_r2'], \n",
    "    bar_width, \n",
    "    color='#00bcd4',\n",
    "    edgecolor='black',\n",
    "    linewidth=1,\n",
    "    alpha=0.8,\n",
    "    label='R$^2$'\n",
    ")\n",
    "ax1.set_xlabel('kernel', fontsize=axis_labelsize)\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(cv_svr_df['kernel'], fontsize=tick_fontsize)\n",
    "ax1.tick_params(axis='y', labelcolor='#00bcd4', labelsize=tick_fontsize)\n",
    "ax1.set_ylim(0, 1.01)\n",
    "ax1.grid(True, axis='y')\n",
    "\n",
    "# Green bars: STD of CV R² (right y-axis)\n",
    "ax2 = ax1.twinx()\n",
    "bars2 = ax2.bar(\n",
    "    x + bar_width/2, \n",
    "    cv_svr_df['std_cv_r2'], \n",
    "    bar_width, \n",
    "    color='#388e3c',\n",
    "    edgecolor='black',\n",
    "    linewidth=1,\n",
    "    alpha=0.8,\n",
    "    label='Std. of R$^2$'\n",
    ")\n",
    "ax2.tick_params(axis='y', labelcolor='#388e3c', labelsize=tick_fontsize)\n",
    "ax2.grid(False)\n",
    "\n",
    "# Combined Legend\n",
    "handles = [\n",
    "    plt.Rectangle((0,0),1,1,color='#00bcd4',ec='black',label='R$^2$'),\n",
    "    plt.Rectangle((0,0),1,1,color='#388e3c',ec='black',label='Std. of R$^2$')\n",
    "]\n",
    "ax1.legend(handles=handles, loc='upper right', fontsize=legend_fontsize)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('../../Comprehensive ML - Files & Plots etc/SVR_bestR2_STD_perKernel.png',\n",
    "            dpi=2000, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db47507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the built-in best_estimator_ (already refitted on full train data) and best_params_\n",
    "best_svr_model  = bayes_cv_svr.best_estimator_\n",
    "best_svr_params = bayes_cv_svr.best_params_\n",
    "print(\"Best SVR Parameters Found:\", best_svr_params)\n",
    "\n",
    "print(\"\\nUsing best SVR model from BayesSearchCV (already trained on all data)...\")\n",
    "\n",
    "y_train_pred = best_svr_model.predict(X_train)\n",
    "y_test_pred  = best_svr_model.predict(X_test)\n",
    "\n",
    "train_mse   = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse    = mean_squared_error(y_test, y_test_pred)\n",
    "train_r2    = r2_score(y_train, y_train_pred)\n",
    "test_r2     = r2_score(y_test, y_test_pred)\n",
    "test_rmse   = np.sqrt(test_mse)\n",
    "test_mape   = mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "test_med_ae = median_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Metric': [\n",
    "        'Training Loss (MSE)', 'Test Loss (MSE)', 'Test RMSE',\n",
    "        'R² Score (Train)', 'R² Score (Test)', 'Test MAPE (%)', 'Test Median AE'\n",
    "    ],\n",
    "    'Value': [\n",
    "        train_mse, test_mse, test_rmse, train_r2, test_r2,\n",
    "        test_mape * 100, test_med_ae\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nModel Evaluation Metrics:\")\n",
    "display(results)\n",
    "\n",
    "# Ensure the directory exists (align to RF/KNN saving pattern)\n",
    "os.makedirs('../Models', exist_ok=True)\n",
    "\n",
    "# Save the trained SVR model\n",
    "with open('../Models/svr_final_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_svr_model, f)\n",
    "\n",
    "print(\"Trained SVR model saved to ../Models/svr_final_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572f0a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model = best_svr_model  # alias\n",
    "\n",
    "figsize = (7, 3)\n",
    "path = '../../Comprehensive ML - Files & Plots etc/'\n",
    "\n",
    "# 1. Learning Curve (neg RMSE)\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    svr_model, X_train, y_train,\n",
    "    cv=5, n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "    scoring='neg_root_mean_squared_error'\n",
    ")\n",
    "train_rmse = -train_scores.mean(1)\n",
    "test_rmse  = -test_scores.mean(1)\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "plt.plot(train_sizes, train_rmse, 'o-', label='Train RMSE')\n",
    "plt.plot(train_sizes, test_rmse,  'o-', label='Test RMSE')\n",
    "plt.xlabel('Training Size')\n",
    "plt.ylabel('RMSE (dB)')\n",
    "plt.title('SVR Learning Curve')\n",
    "plt.legend()\n",
    "plt.savefig(f'{path}SVR_learning_curve.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 2. Residuals\n",
    "y_test_pred = svr_model.predict(X_test)\n",
    "residuals   = y_test - y_test_pred\n",
    "plt.figure(figsize=figsize)\n",
    "plt.scatter(y_test_pred, residuals, alpha=0.5)\n",
    "plt.axhline(0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted PL (dB)')\n",
    "plt.ylabel('Residuals (dB)')\n",
    "plt.title('SVR Residuals')\n",
    "plt.savefig(f'{path}SVR_residuals.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 3. Physics Consistency (PL vs. log(distance))\n",
    "dist     = df_test['distance'].values\n",
    "log_dist = np.log10(dist + 1e-6)\n",
    "slope, intercept, r_value, _, _ = linregress(log_dist, y_test_pred)\n",
    "plt.figure(figsize=figsize)\n",
    "plt.scatter(log_dist, y_test_pred, alpha=0.5)\n",
    "plt.plot(log_dist, intercept + slope * log_dist, 'r--',\n",
    "         label=f'n ~ {slope:.2f}, R²={r_value**2:.2f}')\n",
    "plt.xlabel('log10(Distance)')\n",
    "plt.ylabel('Predicted PL (dB)')\n",
    "plt.title('SVR PL vs. log(Distance)')\n",
    "plt.legend()\n",
    "plt.savefig(f'{path}SVR_physics_consistency.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 4. Predicted vs. Real\n",
    "plt.figure(figsize=figsize)\n",
    "lims = [min(y_test.min(), y_test_pred.min()), max(y_test.max(), y_test_pred.max())]\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.5)\n",
    "plt.plot(lims, lims, 'r--')\n",
    "plt.xlabel('Real PL (dB)')\n",
    "plt.ylabel('Predicted PL (dB)')\n",
    "plt.title('SVR Predicted vs. Real')\n",
    "plt.savefig(f'{path}SVR_pred_vs_real.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f06b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For SVR, the number of support vectors indicates model complexity.\n",
    "# Note: attribute exists after fitting; % of SVs close to 100% often signals overfitting.\n",
    "try:\n",
    "    n_sv = best_svr_model.named_steps['svr'].support_.shape[0]\n",
    "    frac_sv = n_sv / X_train.shape[0]\n",
    "    print(f\"Support vectors: {n_sv} ({frac_sv:.2%} of training samples)\")\n",
    "except Exception as e:\n",
    "    print(\"Could not compute support vector count:\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml001",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
