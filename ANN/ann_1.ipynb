{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0f8180c-d353-46e9-9849-9f390c877476",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: left;\">\n",
    "Neural Networks (NN) - MLP Modeling \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "105bc0a3-2fd6-4a6e-8c65-0819d239c8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for data manipulation and visualization\n",
    "import numpy as np                               # For numerical operations\n",
    "import pandas as pd                              # For data manipulation\n",
    "import matplotlib.pyplot as plt                  # For plotting\n",
    "import seaborn as sns                            # For advanced data visualization\n",
    "\n",
    "# Libraries for model building and training\n",
    "import tensorflow as tf                          # For deep learning framework\n",
    "from keras.models import Sequential              # For creating sequential models\n",
    "from keras.layers import Dense, Input, BatchNormalization, Dropout, LeakyReLU  # Layers for building neural networks\n",
    "from keras.regularizers import l2               # For L2 regularization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau  # For training optimization\n",
    "\n",
    "# Libraries for evaluation and preprocessing\n",
    "from sklearn.metrics import (                   # For model evaluation metrics\n",
    "    mean_squared_error, \n",
    "    r2_score, \n",
    "    mean_absolute_percentage_error, \n",
    "    median_absolute_error\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler # For standardizing features\n",
    "from sklearn.model_selection import KFold, train_test_split # For cross-validation and splitting data\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(50)                              # Seed for NumPy\n",
    "tf.random.set_seed(50)                          # Seed for TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d837f26b-a15c-4f5c-adf4-dd514658a78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "\n",
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 749214 entries, 0 to 749213\n",
      "Data columns (total 20 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   time         749214 non-null  object \n",
      " 1   device_id    749214 non-null  object \n",
      " 2   co2          749214 non-null  float64\n",
      " 3   humidity     749214 non-null  float64\n",
      " 4   pm25         749214 non-null  float64\n",
      " 5   pressure     749214 non-null  float64\n",
      " 6   temperature  749214 non-null  float64\n",
      " 7   rssi         749214 non-null  float64\n",
      " 8   snr          749214 non-null  float64\n",
      " 9   SF           749214 non-null  int64  \n",
      " 10  frequency    749214 non-null  float64\n",
      " 11  f_count      749214 non-null  float64\n",
      " 12  p_count      749214 non-null  float64\n",
      " 13  toa          749214 non-null  float64\n",
      " 14  distance     749214 non-null  int64  \n",
      " 15  c_walls      749214 non-null  int64  \n",
      " 16  w_walls      749214 non-null  int64  \n",
      " 17  exp_pl       749214 non-null  float64\n",
      " 18  n_power      749214 non-null  float64\n",
      " 19  esp          749214 non-null  float64\n",
      "dtypes: float64(14), int64(4), object(2)\n",
      "memory usage: 114.3+ MB\n",
      "\n",
      "First Five Rows of the Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>device_id</th>\n",
       "      <th>co2</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pm25</th>\n",
       "      <th>pressure</th>\n",
       "      <th>temperature</th>\n",
       "      <th>rssi</th>\n",
       "      <th>snr</th>\n",
       "      <th>SF</th>\n",
       "      <th>frequency</th>\n",
       "      <th>f_count</th>\n",
       "      <th>p_count</th>\n",
       "      <th>toa</th>\n",
       "      <th>distance</th>\n",
       "      <th>c_walls</th>\n",
       "      <th>w_walls</th>\n",
       "      <th>exp_pl</th>\n",
       "      <th>n_power</th>\n",
       "      <th>esp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-09-26 11:00:52.542462+00:00</td>\n",
       "      <td>ED3</td>\n",
       "      <td>633.0</td>\n",
       "      <td>54.22</td>\n",
       "      <td>0.58</td>\n",
       "      <td>300.41</td>\n",
       "      <td>23.85</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>10</td>\n",
       "      <td>867.9</td>\n",
       "      <td>94.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.452608</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>88.4</td>\n",
       "      <td>-83.454107</td>\n",
       "      <td>-71.254107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-09-26 11:01:52.383162+00:00</td>\n",
       "      <td>ED3</td>\n",
       "      <td>645.0</td>\n",
       "      <td>54.18</td>\n",
       "      <td>0.32</td>\n",
       "      <td>300.48</td>\n",
       "      <td>23.87</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>9</td>\n",
       "      <td>867.7</td>\n",
       "      <td>95.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.246784</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>91.4</td>\n",
       "      <td>-86.737602</td>\n",
       "      <td>-74.237602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-09-26 11:02:52.425491+00:00</td>\n",
       "      <td>ED3</td>\n",
       "      <td>648.0</td>\n",
       "      <td>54.23</td>\n",
       "      <td>0.58</td>\n",
       "      <td>300.50</td>\n",
       "      <td>23.88</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>9</td>\n",
       "      <td>867.1</td>\n",
       "      <td>96.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.246784</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>93.4</td>\n",
       "      <td>-88.454107</td>\n",
       "      <td>-76.254107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-09-26 11:02:52.426016+00:00</td>\n",
       "      <td>ED3</td>\n",
       "      <td>648.0</td>\n",
       "      <td>54.23</td>\n",
       "      <td>0.58</td>\n",
       "      <td>300.50</td>\n",
       "      <td>23.88</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>9</td>\n",
       "      <td>867.1</td>\n",
       "      <td>96.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.246784</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>93.4</td>\n",
       "      <td>-88.454107</td>\n",
       "      <td>-76.254107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-09-26 11:03:52.481201+00:00</td>\n",
       "      <td>ED3</td>\n",
       "      <td>645.0</td>\n",
       "      <td>54.25</td>\n",
       "      <td>0.33</td>\n",
       "      <td>300.50</td>\n",
       "      <td>23.90</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>9</td>\n",
       "      <td>868.3</td>\n",
       "      <td>97.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.246784</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>93.4</td>\n",
       "      <td>-89.403045</td>\n",
       "      <td>-76.203045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               time device_id    co2  humidity  pm25  \\\n",
       "0  2024-09-26 11:00:52.542462+00:00       ED3  633.0     54.22  0.58   \n",
       "1  2024-09-26 11:01:52.383162+00:00       ED3  645.0     54.18  0.32   \n",
       "2  2024-09-26 11:02:52.425491+00:00       ED3  648.0     54.23  0.58   \n",
       "3  2024-09-26 11:02:52.426016+00:00       ED3  648.0     54.23  0.58   \n",
       "4  2024-09-26 11:03:52.481201+00:00       ED3  645.0     54.25  0.33   \n",
       "\n",
       "   pressure  temperature  rssi   snr  SF  frequency  f_count  p_count  \\\n",
       "0    300.41        23.85 -71.0  12.2  10      867.9     94.0    104.0   \n",
       "1    300.48        23.87 -74.0  12.5   9      867.7     95.0    105.0   \n",
       "2    300.50        23.88 -76.0  12.2   9      867.1     96.0    106.0   \n",
       "3    300.50        23.88 -76.0  12.2   9      867.1     96.0    106.0   \n",
       "4    300.50        23.90 -76.0  13.2   9      868.3     97.0    107.0   \n",
       "\n",
       "        toa  distance  c_walls  w_walls  exp_pl    n_power        esp  \n",
       "0  0.452608        18        1        2    88.4 -83.454107 -71.254107  \n",
       "1  0.246784        18        1        2    91.4 -86.737602 -74.237602  \n",
       "2  0.246784        18        1        2    93.4 -88.454107 -76.254107  \n",
       "3  0.246784        18        1        2    93.4 -88.454107 -76.254107  \n",
       "4  0.246784        18        1        2    93.4 -89.403045 -76.203045  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset and display basic information\n",
    "\n",
    "# Define the path to the dataset\n",
    "dataset_path = '../../all_data_files/cleaned_dataset_per_device.csv'\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found at the specified path: {dataset_path}\")\n",
    "    # Exit the notebook if the dataset is not found\n",
    "    import sys\n",
    "    sys.exit()\n",
    "\n",
    "# Display dataset information\n",
    "print(\"\\nDataset Information:\")\n",
    "df.info()\n",
    "\n",
    "# Display the first five rows for a quick preview\n",
    "print(\"\\nFirst Five Rows of the Dataset:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "856f332a-716e-4132-b7ed-12620d838735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature scaling completed.\n"
     ]
    }
   ],
   "source": [
    "# Extract necessary columns and perform train-test split with normalization\n",
    "\n",
    "# Define feature columns and target\n",
    "feature_columns = [\n",
    "    'distance', \n",
    "    'frequency', \n",
    "    'c_walls', \n",
    "    'w_walls', \n",
    "    'co2', \n",
    "    'humidity', \n",
    "    'pm25', \n",
    "    'pressure', \n",
    "    'temperature', \n",
    "    'snr'\n",
    "]\n",
    "target_column = 'exp_pl'\n",
    "\n",
    "# Verify that all required columns exist in the dataframe\n",
    "missing_columns = set(feature_columns + [target_column]) - set(df.columns)\n",
    "if missing_columns:\n",
    "    raise ValueError(f\"The following required columns are missing in the dataset: {missing_columns}\")\n",
    "\n",
    "# Extract features and target\n",
    "all_features = df[feature_columns].values\n",
    "PL_all = df[target_column].values\n",
    "\n",
    "# Perform train-test split (80-20 split)\n",
    "X_train_all, X_test_all, PL_train_all, PL_test_all = train_test_split(\n",
    "    all_features, \n",
    "    PL_all, \n",
    "    test_size=0.2, \n",
    "    random_state=50\n",
    ")\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform\n",
    "X_train_all_scaled = scaler.fit_transform(X_train_all)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_all_scaled = scaler.transform(X_test_all)\n",
    "\n",
    "print(\"Feature scaling completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea40448-0d34-4ff3-8b00-7c0f726d50f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m55\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m20\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">81</span> (324.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m81\u001b[0m (324.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">71</span> (284.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m71\u001b[0m (284.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> (40.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m10\u001b[0m (40.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m3729/3747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6106.4194 - mae: 74.4590\n",
      "Epoch 1: val_loss improved from inf to 168.29126, saving model to best_ann_model.keras\n",
      "\u001b[1m3747/3747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 6094.4214 - mae: 74.3541 - val_loss: 168.2913 - val_mae: 11.1166 - learning_rate: 0.0010\n",
      "Epoch 2/500\n",
      "\u001b[1m3741/3747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 674.9393 - mae: 20.1115\n",
      "Epoch 2: val_loss improved from 168.29126 to 91.30055, saving model to best_ann_model.keras\n",
      "\u001b[1m3747/3747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 674.9215 - mae: 20.1114 - val_loss: 91.3006 - val_mae: 7.4155 - learning_rate: 0.0010\n",
      "Epoch 3/500\n",
      "\u001b[1m3737/3747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 633.7749 - mae: 19.6117\n",
      "Epoch 3: val_loss improved from 91.30055 to 85.91262, saving model to best_ann_model.keras\n",
      "\u001b[1m3747/3747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 633.7482 - mae: 19.6113 - val_loss: 85.9126 - val_mae: 7.0839 - learning_rate: 0.0010\n",
      "Epoch 4/500\n",
      "\u001b[1m3723/3747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 592.3566 - mae: 18.9322\n",
      "Epoch 4: val_loss improved from 85.91262 to 81.74090, saving model to best_ann_model.keras\n",
      "\u001b[1m3747/3747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 592.2786 - mae: 18.9309 - val_loss: 81.7409 - val_mae: 6.8722 - learning_rate: 0.0010\n",
      "Epoch 5/500\n",
      "\u001b[1m3732/3747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 551.9117 - mae: 18.2505\n",
      "Epoch 5: val_loss improved from 81.74090 to 81.22362, saving model to best_ann_model.keras\n",
      "\u001b[1m3747/3747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 551.8649 - mae: 18.2496 - val_loss: 81.2236 - val_mae: 6.8478 - learning_rate: 0.0010\n",
      "Epoch 6/500\n",
      "\u001b[1m3733/3747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 508.6692 - mae: 17.4781\n",
      "Epoch 6: val_loss improved from 81.22362 to 80.33720, saving model to best_ann_model.keras\n",
      "\u001b[1m3747/3747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 508.6369 - mae: 17.4775 - val_loss: 80.3372 - val_mae: 6.7692 - learning_rate: 0.0010\n",
      "Epoch 7/500\n",
      "\u001b[1m3732/3747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 470.9567 - mae: 16.7646\n",
      "Epoch 7: val_loss improved from 80.33720 to 71.84944, saving model to best_ann_model.keras\n",
      "\u001b[1m3747/3747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 470.9162 - mae: 16.7638 - val_loss: 71.8494 - val_mae: 6.3007 - learning_rate: 0.0010\n",
      "Epoch 8/500\n",
      "\u001b[1m1384/3747\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 440.8326 - mae: 16.2031"
     ]
    }
   ],
   "source": [
    "def create_ann_model(input_dim):\n",
    "    \"\"\"Creates an enhanced ANN model for regression with regularization and improved \n",
    "    architecture.\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_dim,)))  # Explicit Input layer\n",
    "    \n",
    "    # Third Hidden Layer\n",
    "    model.add(Dense(5, kernel_regularizer=l2(0.001)))\n",
    "    model.add(LeakyReLU(negative_slope=0.1))  # Updated parameter\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    # Output Layer\n",
    "    model.add(Dense(1, activation='linear'))  # Output layer for regression\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "input_dim = X_train_all_scaled.shape[1]\n",
    "model = create_ann_model(input_dim)\n",
    "model.summary()\n",
    "\n",
    "# Define Callbacks\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=30,  # Increased patience\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'best_ann_model.keras',  # Changed extension to .keras\n",
    "    monitor='val_loss', \n",
    "    save_best_only=True, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=10,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model with Callbacks\n",
    "history = model.fit(\n",
    "    X_train_all_scaled,\n",
    "    PL_train_all,\n",
    "    validation_split=0.2,\n",
    "    epochs=500,  # Increased epochs to allow more training\n",
    "    batch_size=128,  # Reduced batch size for more frequent updates\n",
    "    verbose=1,\n",
    "    callbacks=[early_stop, model_checkpoint, reduce_lr]\n",
    ")\n",
    "\n",
    "print(\"Model training completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6921dd-1b00-46a0-b1df-a5986af0754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model on training and test data and display metrics in a table\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_loss, train_mae = model.evaluate(X_train_all_scaled, PL_train_all, verbose=0)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_mae = model.evaluate(X_test_all_scaled, PL_test_all, verbose=0)\n",
    "\n",
    "# Predict path loss for the test set\n",
    "PL_pred = model.predict(X_test_all_scaled).flatten()\n",
    "\n",
    "# Calculate additional metrics\n",
    "rmse_test = np.sqrt(mean_squared_error(PL_test_all, PL_pred))\n",
    "r2_test = r2_score(PL_test_all, PL_pred)\n",
    "mape_test = mean_absolute_percentage_error(PL_test_all, PL_pred)\n",
    "median_ae_test = median_absolute_error(PL_test_all, PL_pred)\n",
    "\n",
    "# Create a results DataFrame\n",
    "results = pd.DataFrame({\n",
    "    'Metric': ['Training Loss (MSE)', 'Training MAE', \n",
    "               'Test Loss (MSE)', 'Test MAE', \n",
    "               'Test RMSE', 'R² Score', \n",
    "               'Test MAPE (%)', 'Test Median AE'],\n",
    "    'Value': [train_loss, train_mae, \n",
    "              test_loss, test_mae, \n",
    "              rmse_test, r2_test, \n",
    "              mape_test * 100, median_ae_test]\n",
    "})\n",
    "\n",
    "# Display the results table\n",
    "print(\"\\nModel Evaluation Metrics:\")\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b857659-9149-42ed-bab6-c452189d80f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training history and model predictions\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss (MSE)')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss (MSE)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot MAE\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['mae'], label='Training MAE')\n",
    "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.title('Training and Validation MAE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot predicted vs actual values\n",
    "plt.figure(figsize=(12, 4))\n",
    "sns.scatterplot(x=PL_test_all, y=PL_pred, alpha=0.6, edgecolor='w', s=70)\n",
    "plt.plot([PL_test_all.min(), PL_test_all.max()], [PL_test_all.min(), PL_test_all.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Path Loss')\n",
    "plt.ylabel('Predicted Path Loss')\n",
    "plt.title('Actual vs Predicted Path Loss')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d42bd59-4118-44f4-b4f7-afdd693bd6a1",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: left;\">\n",
    "Cross-Validation\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b34e74-bb1c-427c-822d-e5394d40767b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform K-Fold Cross-Validation to assess model robustness and display results in a table\n",
    "\n",
    "# Define K-Fold Cross Validator\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold = 1\n",
    "cv_results_list = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train_all_scaled):\n",
    "    print(f\"Training fold {fold}...\")\n",
    "    \n",
    "    # Split data into training and validation for the current fold\n",
    "    X_train_fold, X_val_fold = X_train_all_scaled[train_index], X_train_all_scaled[val_index]\n",
    "    PL_train_fold, PL_val_fold = PL_train_all[train_index], PL_train_all[val_index]\n",
    "    \n",
    "    # Create a new instance of the model for each fold\n",
    "    model = create_ann_model(input_dim)\n",
    "    \n",
    "    # Define Callbacks\n",
    "    early_stop_cv = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=30,  # Patience can be adjusted as needed\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    model_checkpoint_cv = ModelCheckpoint(\n",
    "        f'best_ann_model_fold_{fold}.keras', \n",
    "        monitor='val_loss', \n",
    "        save_best_only=True, \n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    reduce_lr_cv = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=10,\n",
    "        min_lr=1e-6,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Train the model on the current fold\n",
    "    history_cv = model.fit(\n",
    "        X_train_fold, \n",
    "        PL_train_fold, \n",
    "        validation_data=(X_val_fold, PL_val_fold),\n",
    "        epochs=500, \n",
    "        batch_size=128, \n",
    "        callbacks=[early_stop_cv, model_checkpoint_cv, reduce_lr_cv],\n",
    "        verbose=0  # Set to 1 for detailed output\n",
    "    )\n",
    "    \n",
    "    # Load the best model from the current fold\n",
    "    best_model = tf.keras.models.load_model(f'best_ann_model_fold_{fold}.keras')\n",
    "    \n",
    "    # Predict path loss for the test set\n",
    "    PL_pred_cv = best_model.predict(X_test_all_scaled).flatten()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    test_loss, test_mae = best_model.evaluate(X_test_all_scaled, PL_test_all, verbose=0)\n",
    "    rmse_cv = np.sqrt(mean_squared_error(PL_test_all, PL_pred_cv))\n",
    "    r2_cv = r2_score(PL_test_all, PL_pred_cv)\n",
    "    mape_cv = mean_absolute_percentage_error(PL_test_all, PL_pred_cv)\n",
    "    median_ae_cv = median_absolute_error(PL_test_all, PL_pred_cv)\n",
    "    \n",
    "    # Append metrics to the results list\n",
    "    cv_results_list.append({\n",
    "        'Fold': fold,\n",
    "        'Test Loss (MSE)': round(test_loss, 4),\n",
    "        'Test MAE': round(test_mae, 4),\n",
    "        'Test RMSE': round(rmse_cv, 4),\n",
    "        'R² Score': round(r2_cv, 4),\n",
    "        'Test MAPE (%)': round(mape_cv * 100, 2),\n",
    "        'Test Median AE': round(median_ae_cv, 4)\n",
    "    })\n",
    "    \n",
    "    print(f\"Fold {fold} - Test Loss (MSE): {test_loss:.4f}, Test MAE: {test_mae:.4f}, RMSE: {rmse_cv:.4f}, R²: {r2_cv:.4f}, MAPE: {mape_cv*100:.2f}%, Median AE: {median_ae_cv:.4f}\\n\")\n",
    "    fold += 1\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "cv_results_df = pd.DataFrame(cv_results_list)\n",
    "\n",
    "# Calculate average and standard deviation for each metric\n",
    "cv_summary = cv_results_df.agg(['mean', 'std']).round(4).reset_index()\n",
    "cv_summary.rename(columns={'index': 'Metric'}, inplace=True)\n",
    "\n",
    "# Display Cross-Validation Results\n",
    "print(\"K-Fold Cross-Validation Results:\")\n",
    "display(cv_results_df)\n",
    "\n",
    "print(\"Cross-Validation Summary:\")\n",
    "display(cv_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_models_env)",
   "language": "python",
   "name": "ml_models_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
