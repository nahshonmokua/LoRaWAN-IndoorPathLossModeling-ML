{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdac93b1-926d-4477-b58c-ab859619f49c",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: left;\">\n",
    "XGBoost for Regression \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bca978da-a18a-41e4-9613-c731fd7eeeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for data manipulation and visualization\n",
    "import numpy as np                               # For numerical operations\n",
    "import pandas as pd                              # For data manipulation\n",
    "import matplotlib.pyplot as plt                  # For plotting\n",
    "import seaborn as sns                            # For advanced data visualization\n",
    "\n",
    "# Libraries for model building and evaluation\n",
    "from sklearn.model_selection import (              # For cross-validation, splitting data, and grid search\n",
    "    KFold, \n",
    "    train_test_split,\n",
    "    ParameterGrid,\n",
    "    GridSearchCV\n",
    ")\n",
    "from sklearn.metrics import (                     # For model evaluation metrics\n",
    "    mean_squared_error, \n",
    "    r2_score, \n",
    "    mean_absolute_percentage_error, \n",
    "    median_absolute_error\n",
    ")\n",
    "\n",
    "# XGBoost library\n",
    "import xgboost as xgb                             # For XGBoost Regressor\n",
    "\n",
    "# ================================\n",
    "# Set Seed for Reproducibility\n",
    "# ================================\n",
    "RANDOM_STATE = 50\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a455b69-7f83-43a4-adf7-86cb1cce21cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "\n",
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 607907 entries, 0 to 607906\n",
      "Data columns (total 20 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   time         607907 non-null  object \n",
      " 1   device_id    607907 non-null  object \n",
      " 2   co2          607907 non-null  float64\n",
      " 3   humidity     607907 non-null  float64\n",
      " 4   pm25         607907 non-null  float64\n",
      " 5   pressure     607907 non-null  float64\n",
      " 6   temperature  607907 non-null  float64\n",
      " 7   rssi         607907 non-null  float64\n",
      " 8   snr          607907 non-null  float64\n",
      " 9   SF           607907 non-null  int64  \n",
      " 10  frequency    607907 non-null  float64\n",
      " 11  f_count      607907 non-null  float64\n",
      " 12  p_count      607907 non-null  float64\n",
      " 13  toa          607907 non-null  float64\n",
      " 14  distance     607907 non-null  int64  \n",
      " 15  c_walls      607907 non-null  int64  \n",
      " 16  w_walls      607907 non-null  int64  \n",
      " 17  exp_pl       607907 non-null  float64\n",
      " 18  n_power      607907 non-null  float64\n",
      " 19  esp          607907 non-null  float64\n",
      "dtypes: float64(14), int64(4), object(2)\n",
      "memory usage: 92.8+ MB\n",
      "\n",
      "First Five Rows of the Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>device_id</th>\n",
       "      <th>co2</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pm25</th>\n",
       "      <th>pressure</th>\n",
       "      <th>temperature</th>\n",
       "      <th>rssi</th>\n",
       "      <th>snr</th>\n",
       "      <th>SF</th>\n",
       "      <th>frequency</th>\n",
       "      <th>f_count</th>\n",
       "      <th>p_count</th>\n",
       "      <th>toa</th>\n",
       "      <th>distance</th>\n",
       "      <th>c_walls</th>\n",
       "      <th>w_walls</th>\n",
       "      <th>exp_pl</th>\n",
       "      <th>n_power</th>\n",
       "      <th>esp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-09-26 11:02:08.387851+00:00</td>\n",
       "      <td>ED0</td>\n",
       "      <td>539.0</td>\n",
       "      <td>49.34</td>\n",
       "      <td>0.39</td>\n",
       "      <td>299.69</td>\n",
       "      <td>24.57</td>\n",
       "      <td>-48.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>9</td>\n",
       "      <td>867.5</td>\n",
       "      <td>82.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.246784</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65.4</td>\n",
       "      <td>-57.073822</td>\n",
       "      <td>-48.573822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-09-26 11:03:08.309590+00:00</td>\n",
       "      <td>ED0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>49.33</td>\n",
       "      <td>0.80</td>\n",
       "      <td>299.77</td>\n",
       "      <td>24.59</td>\n",
       "      <td>-48.0</td>\n",
       "      <td>12.8</td>\n",
       "      <td>8</td>\n",
       "      <td>867.3</td>\n",
       "      <td>83.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.133632</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65.4</td>\n",
       "      <td>-61.022142</td>\n",
       "      <td>-48.222142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-09-26 11:04:08.368448+00:00</td>\n",
       "      <td>ED0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>49.28</td>\n",
       "      <td>0.71</td>\n",
       "      <td>299.70</td>\n",
       "      <td>24.62</td>\n",
       "      <td>-48.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>868.5</td>\n",
       "      <td>84.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.133632</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65.4</td>\n",
       "      <td>-56.638920</td>\n",
       "      <td>-48.638920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-09-26 11:05:08.405529+00:00</td>\n",
       "      <td>ED0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>49.34</td>\n",
       "      <td>0.56</td>\n",
       "      <td>299.69</td>\n",
       "      <td>24.63</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8</td>\n",
       "      <td>867.9</td>\n",
       "      <td>85.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.133632</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66.4</td>\n",
       "      <td>-60.331956</td>\n",
       "      <td>-49.331956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-09-26 11:06:08.455112+00:00</td>\n",
       "      <td>ED0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>49.28</td>\n",
       "      <td>0.60</td>\n",
       "      <td>299.73</td>\n",
       "      <td>24.64</td>\n",
       "      <td>-46.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>8</td>\n",
       "      <td>867.5</td>\n",
       "      <td>86.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0.133632</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63.4</td>\n",
       "      <td>-55.693058</td>\n",
       "      <td>-46.493058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               time device_id    co2  humidity  pm25  \\\n",
       "0  2024-09-26 11:02:08.387851+00:00       ED0  539.0     49.34  0.39   \n",
       "1  2024-09-26 11:03:08.309590+00:00       ED0  540.0     49.33  0.80   \n",
       "2  2024-09-26 11:04:08.368448+00:00       ED0  537.0     49.28  0.71   \n",
       "3  2024-09-26 11:05:08.405529+00:00       ED0  537.0     49.34  0.56   \n",
       "4  2024-09-26 11:06:08.455112+00:00       ED0  534.0     49.28  0.60   \n",
       "\n",
       "   pressure  temperature  rssi   snr  SF  frequency  f_count  p_count  \\\n",
       "0    299.69        24.57 -48.0   8.5   9      867.5     82.0    109.0   \n",
       "1    299.77        24.59 -48.0  12.8   8      867.3     83.0    110.0   \n",
       "2    299.70        24.62 -48.0   8.0   8      868.5     84.0    111.0   \n",
       "3    299.69        24.63 -49.0  11.0   8      867.9     85.0    112.0   \n",
       "4    299.73        24.64 -46.0   9.2   8      867.5     86.0    113.0   \n",
       "\n",
       "        toa  distance  c_walls  w_walls  exp_pl    n_power        esp  \n",
       "0  0.246784        10        0        0    65.4 -57.073822 -48.573822  \n",
       "1  0.133632        10        0        0    65.4 -61.022142 -48.222142  \n",
       "2  0.133632        10        0        0    65.4 -56.638920 -48.638920  \n",
       "3  0.133632        10        0        0    66.4 -60.331956 -49.331956  \n",
       "4  0.133632        10        0        0    63.4 -55.693058 -46.493058  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the path to the dataset\n",
    "dataset_path = '../../all_data_files/cleaned_dataset_per_device.csv'\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found at the specified path: {dataset_path}\")\n",
    "    import sys\n",
    "    sys.exit()\n",
    "\n",
    "# Display dataset information\n",
    "print(\"\\nDataset Information:\")\n",
    "df.info()\n",
    "print(\"\\nFirst Five Rows of the Dataset:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "907b6372-1bd1-47b3-a448-48eda149697e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-test split completed.\n"
     ]
    }
   ],
   "source": [
    "# Define feature columns and target\n",
    "feature_columns = [\n",
    "    'distance', 'frequency', 'c_walls', 'w_walls', \n",
    "    'co2', 'humidity', 'pm25', 'pressure', \n",
    "    'temperature', 'snr'\n",
    "]\n",
    "target_column = 'exp_pl'\n",
    "\n",
    "# Verify that all required columns exist\n",
    "missing_columns = set(feature_columns + [target_column]) - set(df.columns)\n",
    "if missing_columns:\n",
    "    raise ValueError(f\"The following required columns are missing in the dataset: {missing_columns}\")\n",
    "\n",
    "# Extract features and target\n",
    "all_features = df[feature_columns].values\n",
    "PL_all = df[target_column].values\n",
    "\n",
    "# Perform train-test split (80-20 split)\n",
    "X_train_all, X_test_all, PL_train_all, PL_test_all = train_test_split(\n",
    "    all_features, PL_all, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"\\nTrain-test split completed...\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6ffad7-eca4-4706-b672-54e858d764f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Grid Search for max_depth=1...\n"
     ]
    }
   ],
   "source": [
    "# Define max_depth values and an expanded parameter grid\n",
    "max_depth_values = [1, 2, 3]\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'reg_alpha': [0, 0.1, 1],\n",
    "    'reg_lambda': [1, 1.5, 2]\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "best_params_per_depth = {}\n",
    "best_scores_per_depth = {}\n",
    "\n",
    "# Pre-create the DMatrix to avoid repeated computation\n",
    "dtrain = xgb.DMatrix(X_train_all, label=PL_train_all)\n",
    "\n",
    "for depth in max_depth_values:\n",
    "    print(f\"\\nPerforming Grid Search for max_depth={depth}...\")\n",
    "    best_mse = float('inf')\n",
    "    best_params = None\n",
    "    best_num_boost_round = 0\n",
    "\n",
    "    # Iterate over all combinations in the parameter grid\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        # Extract and remove 'n_estimators' from params\n",
    "        n_estimators = params.pop('n_estimators')\n",
    "\n",
    "        # Add parameters specific to the current max_depth\n",
    "        params.update({\n",
    "            'max_depth': depth,\n",
    "            'objective': 'reg:squarederror',\n",
    "            'random_state': RANDOM_STATE,\n",
    "            'n_jobs': -1\n",
    "        })\n",
    "\n",
    "        # Perform cross-validation with num_boost_round set to n_estimators\n",
    "        cv_results = xgb.cv(\n",
    "            params=params,\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=n_estimators,  # Set num_boost_round to n_estimators\n",
    "            nfold=5,\n",
    "            metrics='rmse',\n",
    "            early_stopping_rounds=10,\n",
    "            seed=RANDOM_STATE,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "\n",
    "        # Extract the best RMSE and corresponding number of boosting rounds\n",
    "        mean_rmse = cv_results['test-rmse-mean'].min()\n",
    "        mse = mean_rmse ** 2\n",
    "        best_round = cv_results['test-rmse-mean'].idxmin() + 1  # +1 because indexing starts at 0\n",
    "\n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_params = params.copy()\n",
    "            best_params['num_boost_round'] = best_round  # Update num_boost_round based on CV\n",
    "\n",
    "    # Extract 'num_boost_round' from best_params and remove it\n",
    "    num_boost_round = best_params.pop('num_boost_round')\n",
    "\n",
    "    # Train the final model with the best parameters\n",
    "    final_model = xgb.train(best_params, dtrain, num_boost_round=num_boost_round)\n",
    "\n",
    "    # Store the best model and its parameters\n",
    "    best_models[depth] = final_model\n",
    "    best_params_per_depth[depth] = best_params\n",
    "    best_scores_per_depth[depth] = best_mse\n",
    "\n",
    "    print(f\"\\nBest Parameters for max_depth={depth}: {best_params}\")\n",
    "    print(f\"\\nBest CV MSE for max_depth={depth}: {best_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c039aae1-e120-44bd-b965-56ca0abbc844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store evaluation metrics for each model\n",
    "evaluation_metrics = []\n",
    "\n",
    "for depth in max_depth_values:\n",
    "    model = best_models[depth]\n",
    "    params = best_params_per_depth[depth]\n",
    "    \n",
    "    print(f\"\\nEvaluating model with max_depth={depth} and parameters: {params}\")\n",
    "    \n",
    "    # Make predictions on the training set\n",
    "    PL_train_pred = model.predict(xgb.DMatrix(X_train_all))\n",
    "    # Make predictions on the test set\n",
    "    PL_test_pred = model.predict(xgb.DMatrix(X_test_all))\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_mse = mean_squared_error(PL_train_all, PL_train_pred)\n",
    "    test_mse = mean_squared_error(PL_test_all, PL_test_pred)\n",
    "    train_r2 = r2_score(PL_train_all, PL_train_pred)\n",
    "    test_r2 = r2_score(PL_test_all, PL_test_pred)\n",
    "    test_rmse = np.sqrt(test_mse)\n",
    "    test_mape = mean_absolute_percentage_error(PL_test_all, PL_test_pred)\n",
    "    test_median_ae = median_absolute_error(PL_test_all, PL_test_pred)\n",
    "    \n",
    "    # Append metrics to the list\n",
    "    evaluation_metrics.append({\n",
    "        'max_depth': depth,\n",
    "        'Training Loss (MSE)': train_mse,\n",
    "        'Test Loss (MSE)': test_mse,\n",
    "        'Test RMSE': test_rmse,\n",
    "        'R² Score': test_r2,\n",
    "        'Test MAPE (%)': test_mape * 100,\n",
    "        'Test Median AE': test_median_ae\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nModel with max_depth={depth} - Training MSE: {train_mse:.4f}, Test MSE: {test_mse:.4f}\")\n",
    "    print(f\"\\nTraining R²: {train_r2:.4f}, Test R²: {test_r2:.4f}\")\n",
    "    print(f\"\\nTest RMSE: {test_rmse:.4f}, Test MAPE: {test_mape*100:.2f}%, Test Median AE: {test_median_ae:.4f}\")\n",
    "\n",
    "# Create a results DataFrame\n",
    "results_df = pd.DataFrame(evaluation_metrics)\n",
    "\n",
    "print(\"\\nModel Evaluation Metrics for Best Models per max_depth:\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c929e6f0-8138-4573-ae5d-28e54e78eae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of models\n",
    "num_models = len(max_depth_values)\n",
    "\n",
    "# Set up the subplot grid (1 row, 3 columns)\n",
    "fig, axes = plt.subplots(1, num_models, figsize=(18, 5), sharey=True)\n",
    "\n",
    "# If only one subplot, make axes iterable\n",
    "if num_models == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, depth in zip(axes, max_depth_values):\n",
    "    model = best_models[depth]\n",
    "    # Make predictions using DMatrix\n",
    "    PL_test_pred = model.predict(xgb.DMatrix(X_test_all))\n",
    "    \n",
    "    sns.scatterplot(x=PL_test_all, y=PL_test_pred, alpha=0.5, edgecolor='w', s=50, ax=ax)\n",
    "    ax.plot([PL_test_all.min(), PL_test_all.max()], [PL_test_all.min(), PL_test_all.max()], 'r--', lw=2)\n",
    "    ax.set_xlabel('Actual Path Loss')\n",
    "    ax.set_ylabel('Predicted Path Loss')\n",
    "    ax.set_title(f'Actual vs Predicted Path Loss (max_depth={depth})')\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19edf2b2-787f-4f03-bbff-31ce779bcce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Cross-Validation on Best Models\n",
    "# ================================\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_folds = 5\n",
    "\n",
    "# Initialize KFold with consistent RANDOM_STATE\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Dictionary to store cross-validation results\n",
    "cv_results_dict = {depth: [] for depth in max_depth_values}\n",
    "\n",
    "print(\"\\nPerforming K-Fold Cross-Validation for Each Best Model...\\n\")\n",
    "\n",
    "for depth in max_depth_values:\n",
    "    params = best_params_per_depth[depth]\n",
    "    \n",
    "    print(f\"\\nCross-Validation for max_depth={depth} with parameters: {params}\")\n",
    "    \n",
    "    # Instantiate the XGBRegressor with best parameters\n",
    "    xgb_cv = xgb.XGBRegressor(\n",
    "        max_depth=depth,\n",
    "        n_estimators=params['n_estimators'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        subsample=params['subsample'],\n",
    "        colsample_bytree=params['colsample_bytree'],\n",
    "        min_child_weight=params['min_child_weight'],\n",
    "        gamma=params['gamma'],\n",
    "        objective='reg:squarederror',\n",
    "        random_state=RANDOM_STATE, \n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Perform manual cross-validation to calculate all metrics\n",
    "    \n",
    "    fold = 1 # Reset fold counter for each depth\n",
    "    for train_idx, val_idx in kf.split(X_train_all):\n",
    "        # Split the data for the current fold\n",
    "        X_train_fold, X_val_fold = X_train_all[train_idx], X_train_all[val_idx]\n",
    "        PL_train_fold, PL_val_fold = PL_train_all[train_idx], PL_train_all[val_idx]\n",
    "        \n",
    "        # Train the model on the current fold\n",
    "        xgb_cv.fit(X_train_fold, PL_train_fold)\n",
    "        \n",
    "        # Predict on validation set\n",
    "        PL_val_pred = xgb_cv.predict(X_val_fold)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        val_mse = mean_squared_error(PL_val_fold, PL_val_pred)\n",
    "        val_rmse = np.sqrt(val_mse)\n",
    "        val_r2 = r2_score(PL_val_fold, PL_val_pred)\n",
    "        val_mape = mean_absolute_percentage_error(PL_val_fold, PL_val_pred)\n",
    "        val_median_ae = median_absolute_error(PL_val_fold, PL_val_pred)\n",
    "        \n",
    "        # Append metrics to the dictionary\n",
    "        cv_results_dict[depth].append({\n",
    "            'Fold': fold,\n",
    "            'Validation Loss (MSE)': round(val_mse, 4),\n",
    "            'Validation RMSE': round(val_rmse, 4),\n",
    "            'R² Score': round(val_r2, 4),\n",
    "            'Validation MAPE (%)': round(val_mape * 100, 2),\n",
    "            'Validation Median AE': round(val_median_ae, 4)\n",
    "        })\n",
    "\n",
    "        # Print metrics for the current fold\n",
    "        print(f\" Fold {fold} - MSE: {val_mse:.4f}, RMSE: {val_rmse:.4f}, R²: {val_r2:.4f}, MAPE: {val_mape*100:.2f}%, Median AE: {val_median_ae:.4f} \\n\")\n",
    "        fold += 1\n",
    "\n",
    "# ================================\n",
    "# Display Cross-Validation Results\n",
    "# ================================\n",
    "for depth in max_depth_values:\n",
    "    print(f\"\\nK-Fold Cross-Validation Results for max_depth={depth}:\")\n",
    "    cv_results_df = pd.DataFrame(cv_results_dict[depth])\n",
    "    display(cv_results_df)\n",
    "    \n",
    "    # Summary statistics\n",
    "    cv_summary = cv_results_df.agg(['mean', 'std']).round(4).reset_index()\n",
    "    cv_summary.rename(columns={'index': 'Metric'}, inplace=True)\n",
    "\n",
    "    # Transposing the summary for better readability\n",
    "    cv_summary_transposed = cv_summary.set_index('Metric').T\n",
    "    \n",
    "    print(f\"\\nCross-Validation Summary for max_depth={depth}:\")\n",
    "    display(cv_summary_transposed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_models_env)",
   "language": "python",
   "name": "ml_models_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
